# ğŸ­ EmotionHand ä¸“ä¸šçº§æƒ…ç»ªæ‰‹åŠ¿è¯†åˆ«ç³»ç»Ÿ - å®Œæ•´ä»£ç æŒ‡å—

> **ä¼ä¸šçº§EMG+GSRä¿¡å·å¤„ç† + 3Då®æ—¶å¯è§†åŒ–ç³»ç»Ÿ**
>
> åŸºäºä¸“ä¸šé¢„å¤„ç†é“ä¸‰è§’ï¼šä¿¡å·â†’æ—¶é—´çª—â†’å½’ä¸€åŒ– | å¹²å‡€ã€ç¨³å®šã€ä½å»¶è¿Ÿ

## ğŸ“‹ ç³»ç»Ÿæ¦‚è§ˆ

```
ğŸ¯ EmotionHand v2.0 - ä¼ä¸šçº§æ¶æ„
â”œâ”€â”€ ğŸ“š æ–‡æ¡£ç³»ç»Ÿ
â”‚   â”œâ”€â”€ PROFESSIONAL_SIGNAL_PROCESSING_GUIDE.md  # ä¸“ä¸šä¿¡å·å¤„ç†æŒ‡å—
â”‚   â”œâ”€â”€ COMPLETE_CODE_GUIDE_V2.md              # æœ¬æ–‡æ¡£
â”‚   â””â”€â”€ README.md                            # é¡¹ç›®è¯´æ˜
â”‚
â”œâ”€â”€ ğŸ§  æ ¸å¿ƒå¤„ç†å¼•æ“
â”‚   â”œâ”€â”€ signal_processing_engine.py          # ä¿¡å·å¤„ç†æ ¸å¿ƒå¼•æ“
â”‚   â”œâ”€â”€ signal_processing_config.json        # é…ç½®é©±åŠ¨å‚æ•°
â”‚   â”œâ”€â”€ calibration_system.py              # ä¸ªä½“åŒ–æ ¡å‡†ç³»ç»Ÿ
â”‚   â””â”€â”€ emotion_state_detector.py          # æ™ºèƒ½æƒ…ç»ªè¯†åˆ«
â”‚
â”œâ”€â”€ ğŸ“Š å¯è§†åŒ–ç³»ç»Ÿ
â”‚   â”œâ”€â”€ visualize_hand_3d_optimized.py   # ä¼˜åŒ–3Dæ‰‹åŠ¿å¯è§†åŒ–
â”‚   â””â”€â”€ realtime_emotion_visualizer.py    # å®æ—¶æƒ…ç»ªç›‘æµ‹ç³»ç»Ÿ
â”‚
â”œâ”€â”€ ğŸ¨ é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ 3d_visualization_config.json       # 3Då¯è§†åŒ–å‚æ•°
â”‚   â””â”€â”€ emotionhand_config.json           # ç³»ç»Ÿé…ç½®
â”‚
â”œâ”€â”€ ğŸ§ª æ•°æ®ä¸æµ‹è¯•
â”‚   â””â”€â”€ data_collector.py                # æ•°æ®é‡‡é›†å·¥å…·
â”‚
â””â”€â”€ ğŸš€ å¯åŠ¨è„šæœ¬
    â”œâ”€â”€ demo_optimized.py                 # ä¼˜åŒ–ç‰ˆæ¼”ç¤º
    â””â”€â”€ run_professional_demo.py          # ä¸“ä¸šç³»ç»Ÿå¯åŠ¨å™¨
```

---

## ğŸš€ å¿«é€Ÿå¯åŠ¨æŒ‡å—

### 1. ç¯å¢ƒå‡†å¤‡
```bash
# å®‰è£…ä¾èµ–
pip install numpy scipy matplotlib pandas pathlib

# æˆ–ä½¿ç”¨conda
conda install numpy scipy matplotlib pandas
```

### 2. å¿«é€Ÿå¯åŠ¨å‘½ä»¤
```bash
# ğŸ­ å¯åŠ¨ä¸“ä¸šå®æ—¶å¯è§†åŒ–ç³»ç»Ÿ
python realtime_emotion_visualizer.py

# ğŸ¨ å¯åŠ¨ä¼˜åŒ–3Dæ‰‹åŠ¿æ¼”ç¤º
python visualize_hand_3d_optimized.py

# ğŸ”§ è¿è¡Œä¸ªä½“åŒ–æ ¡å‡†
python calibration_system.py

# ğŸ§ª æµ‹è¯•ä¿¡å·å¤„ç†å¼•æ“
python signal_processing_engine.py
```

### 3. ç³»ç»Ÿæ¼”ç¤ºé€‰æ‹©å™¨
```bash
# åˆ›å»ºæ™ºèƒ½å¯åŠ¨è„šæœ¬
python -c "
import os
print('ğŸ­ EmotionHand æ¼”ç¤ºç³»ç»Ÿ')
print('=' * 40)
print('1. ä¸“ä¸šå®æ—¶å¯è§†åŒ–ç³»ç»Ÿ')
print('2. 3Dæ‰‹åŠ¿ä¼˜åŒ–æ¼”ç¤º')
print('3. ä¸ªä½“åŒ–æ ¡å‡†ç³»ç»Ÿ')
print('4. ä¿¡å·å¤„ç†å¼•æ“æµ‹è¯•')
choice = input('è¯·é€‰æ‹©æ¼”ç¤º (1-4): ')
if choice == '1':
    os.system('python realtime_emotion_visualizer.py')
elif choice == '2':
    os.system('python visualize_hand_3d_optimized.py')
elif choice == '3':
    os.system('python calibration_system.py')
elif choice == '4':
    os.system('python signal_processing_engine.py')
"
```

---

## ğŸ“¦ æ ¸å¿ƒæ¨¡å—è¯¦è§£

### 1. signal_processing_engine.py - ä¿¡å·å¤„ç†å¼•æ“

**åŠŸèƒ½**: ä¼ä¸šçº§EMG+GSRä¿¡å·å¤„ç†æ ¸å¿ƒ
```python
# åŸºç¡€ä½¿ç”¨
from signal_processing_engine import RealTimeSignalProcessor

# åˆå§‹åŒ–å¤„ç†å™¨
processor = RealTimeSignalProcessor('signal_processing_config.json')
processor.start()

# æ·»åŠ æ•°æ®
emg_data = [0.1, 0.2, 0.15, 0.8]  # 8é€šé“EMG
gsr_data = 0.25                         # GSRä¿¡å·
processor.add_data(emg_data, gsr_data)

# å¤„ç†çª—å£
result = processor.process_window()
print(f"è´¨é‡è¯„åˆ†: {result['quality']['overall']:.2f}")
print(f"å¤„ç†å»¶è¿Ÿ: {result['processing_time']*1000:.1f}ms")

# æ€§èƒ½ç»Ÿè®¡
stats = processor.get_performance_stats()
print(f"å¤„ç†FPS: {stats['fps']:.1f}")
```

**æ ¸å¿ƒç‰¹æ€§**:
- âœ… **EMGå¤„ç†**: 20-450Hzå¸¦é€š + 50/60Hzå·¥é¢‘é™·æ³¢
- âœ… **GSRå¤„ç†**: åŸºè°ƒ/ååº”åˆ†ç¦» + SCRå³°æ£€æµ‹
- âœ… **ç‰¹å¾æå–**: RMS, MDF, ZC, WL, é¢‘å¸¦èƒ½é‡
- âœ… **è´¨é‡ç›‘æµ‹**: SNR>6dB, å¤¹é¡¶ç‡<1%, 5Ïƒå¼‚å¸¸æ£€æµ‹
- âœ… **å®æ—¶æ€§èƒ½**: <100mså»¶è¿Ÿ, 15-30 FPS

---

### 2. calibration_system.py - ä¸ªä½“åŒ–æ ¡å‡†

**åŠŸèƒ½**: 60ç§’å¿«é€Ÿæ ¡å‡†ï¼Œå»ºç«‹ä¸ªäººç”Ÿç†åŸºçº¿
```python
# æ ¡å‡†æµç¨‹
from calibration_system import CalibrationSystem
import json

# åŠ è½½é…ç½®
with open('signal_processing_config.json', 'r') as f:
    config = json.load(f)

# åˆ›å»ºæ ¡å‡†ç³»ç»Ÿ
calibrator = CalibrationSystem(config)

# å¯åŠ¨æ ¡å‡†
success = calibrator.start_calibration("user_001")

# æŸ¥çœ‹å¯ç”¨æ¡£æ¡ˆ
profiles = calibrator.get_available_profiles()
print(f"å¯ç”¨æ ¡å‡†æ¡£æ¡ˆ: {profiles}")
```

**æ ¡å‡†æµç¨‹**:
1. **é™æ¯é˜¶æ®µ** (30ç§’): å®Œå…¨æ”¾æ¾ï¼Œé‡‡é›†åŸºçº¿
2. **æ´»åŠ¨é˜¶æ®µ** (30ç§’): è½»æ¡ç»ƒä¹ ï¼Œé‡‡é›†æ´»åŠ¨èŒƒå›´
3. **è‡ªåŠ¨è®¡ç®—**: åˆ†ä½å½’ä¸€åŒ–å‚æ•°ï¼Œè´¨é‡è¯„ä¼°
4. **æ¡£æ¡ˆä¿å­˜**: JSONæ ¼å¼ï¼Œä¸‹æ¬¡ç›´æ¥åŠ è½½

---

### 3. emotion_state_detector.py - æƒ…ç»ªçŠ¶æ€æ£€æµ‹

**åŠŸèƒ½**: åŸºäºç”Ÿç†ç‰¹å¾çš„æƒ…ç»ªçŠ¶æ€è¯†åˆ«
```python
# æƒ…ç»ªæ£€æµ‹
from emotion_state_detector import EnsembleDetector
import json

# åˆå§‹åŒ–æ£€æµ‹å™¨
with open('signal_processing_config.json', 'r') as f:
    config = json.load(f)

detector = EnsembleDetector(config)

# é¢„æµ‹æƒ…ç»ªçŠ¶æ€
features = {'rms': 0.4, 'mdf': 0.7, 'gsr_tonic': 0.4}
prediction = detector.predict_state(features, {}, {})

print(f"æƒ…ç»ªçŠ¶æ€: {prediction.state.value}")
print(f"ç½®ä¿¡åº¦: {prediction.confidence:.2f}")
print(f"æ¨ç†è¿‡ç¨‹: {prediction.reasoning}")
```

**è¯†åˆ«è§„åˆ™**:
- **æ”¾æ¾**: RMS<0.25 && GSR<0.25
- **ä¸“æ³¨**: 0.25<RMS<0.55 && 0.25<GSR<0.55 && MDFâ‰¥0.5
- **ç´§å¼ **: RMS>0.55 && GSR>0.55 && MDF>0.6
- **ç–²åŠ³**: RMSä¸‹é™ && MDF<0.35 (æŒç»­â‰¥30s)

---

### 4. realtime_emotion_visualizer.py - å®æ—¶ç›‘æµ‹ç³»ç»Ÿ

**åŠŸèƒ½**: ä¸‰é¢æ¿ä¸“ä¸šå®æ—¶å¯è§†åŒ–
```python
# å¯åŠ¨å®æ—¶å¯è§†åŒ–
from realtime_emotion_visualizer import RealtimeEmotionVisualizer

# åˆ›å»ºç³»ç»Ÿ
visualizer = RealtimeEmotionVisualizer()

# æ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡
visualizer.show_performance_stats()

# å¯åŠ¨å¯è§†åŒ–
visualizer.start_visualization()
```

**ç•Œé¢å¸ƒå±€**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ç³»ç»Ÿæ ‡é¢˜                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   ğŸ­ æƒ…ç»ªçŠ¶æ€ç›‘æµ‹    â”‚    ğŸ“Š 3Dæ‰‹åŠ¿å¯è§†åŒ–            â”‚
â”‚   â€¢ çŠ¶æ€æ—¶é—´çº¿       â”‚    â€¢ åŠ¨æ€æ‰‹åŠ¿æ¨¡å‹              â”‚
â”‚   â€¢ ç½®ä¿¡åº¦æ˜¾ç¤º       â”‚    â€¢ æƒ…ç»ªé¢œè‰²æ˜ å°„              â”‚
â”‚   â€¢ æ¨ç†è¯´æ˜         â”‚    â€¢ å®æ—¶æ•°æ®é©±åŠ¨              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   ğŸ“¡ ä¿¡å·è´¨é‡ç›‘æµ‹    â”‚    âš™ï¸ ç³»ç»ŸçŠ¶æ€                â”‚
â”‚   â€¢ EMG/GSRè´¨é‡æ›²çº¿  â”‚    â€¢ FPSæ˜¾ç¤º                  â”‚
â”‚   â€¢ SNR/å¤¹é¡¶ç‡       â”‚    â€¢ å»¶è¿Ÿç›‘æ§                  â”‚
â”‚   â€¢ è¿æ¥çŠ¶æ€         â”‚    â€¢ ç»Ÿè®¡ä¿¡æ¯                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 5. visualize_hand_3d_optimized.py - 3Dæ‰‹åŠ¿å¯è§†åŒ–

**åŠŸèƒ½**: ä¼˜åŒ–ç‰ˆ3Dæ‰‹éƒ¨æ¨¡å‹æ¸²æŸ“
```python
# 3Dæ‰‹åŠ¿æ¼”ç¤º
from visualize_hand_3d_optimized import HandVisualizationSystem
import time

# åˆ›å»ºç³»ç»Ÿ
viz_system = HandVisualizationSystem()

# å®æ—¶æ•°æ®æ¨¡æ‹Ÿ
while True:
    # æ¨¡æ‹Ÿæ•°æ®è¾“å…¥
    emg_data = [np.random.randn() * 0.5 for _ in range(8)]
    gsr_data = 0.2 + np.random.randn() * 0.05

    viz_system.update_data(emg_data, gsr_data)
    viz_system.update_visualization()

    time.sleep(0.067)  # 15 FPS
```

**è§†è§‰æ•ˆæœ**:
- âœ… **éœ‡æ’¼3Dæ¨¡å‹**: åŠé€æ˜æ‰‹æŒ + æ¸å˜è‰²æ‰‹æŒ‡
- âœ… **åŠ¨æ€æ‰‹åŠ¿**: åŸºäºRMSå€¼çš„å®æ—¶æ‰‹åŠ¿å˜åŒ–
- âœ… **æƒ…ç»ªæ˜ å°„**: çŠ¶æ€é©±åŠ¨çš„é¢œè‰²å˜åŒ–
- âœ… **ç²’å­æ•ˆæœ**: èƒŒæ™¯ç²’å­å¢å¼ºè§†è§‰å†²å‡»
- âœ… **æ€§èƒ½ä¼˜åŒ–**: 15FPSæµç•…æ¸²æŸ“

---

## âš™ï¸ é…ç½®ç³»ç»Ÿè¯¦è§£

### signal_processing_config.json
```json
{
  "emg": {
    "sample_rate": 1000,        // EMGé‡‡æ ·ç‡
    "notch_freq": 50,           // å·¥é¢‘é™·æ³¢é¢‘ç‡
    "channels": 8               // EMGé€šé“æ•°
  },
  "window": {
    "size": 256,               // çª—é•¿ (ms)
    "overlap_ratio": 0.75,       // é‡å ç‡
    "step_size": 64             // æ­¥é•¿ (ms)
  },
  "realtime": {
    "target_fps": 15,           // ç›®æ ‡å¸§ç‡
    "max_latency_ms": 100        // æœ€å¤§å»¶è¿Ÿ
  },
  "emotional_states": {
    "thresholds": {
      "relaxed": {"rms_max": 0.25, "gsr_max": 0.25},
      "focused": {"rms_min": 0.25, "rms_max": 0.55},
      "stressed": {"rms_min": 0.55, "gsr_min": 0.55}
    }
  }
}
```

### 3d_visualization_config.json
```json
{
  "palm_length": 0.85,
  "palm_width": 0.85,
  "finger_lengths": [0.65, 0.75, 0.70, 0.55],
  "gesture_bends": {
    "Fist": [85, 80, 75, 70],
    "Open": [5, 5, 5, 5],
    "Pinch": [10, 75, 80, 85],
    "Point": [10, 10, 10, 80]
  },
  "state_colors": {
    "Relaxed": "#3498db",
    "Focused": "#2ecc71",
    "Stressed": "#e74c3c",
    "Fatigued": "#f39c12"
  }
}
```

---

## ğŸ¨ æ¼”ç¤ºè„šæœ¬é›†åˆ

### demo_optimized.py - ç»Ÿä¸€æ¼”ç¤ºå…¥å£
```python
#!/usr/bin/env python3
"""
EmotionHand ç»Ÿä¸€æ¼”ç¤ºå…¥å£
æä¾›å¤šç§æ¼”ç¤ºæ¨¡å¼çš„ä¾¿æ·è®¿é—®
"""

def main():
    print("ğŸ­ EmotionHand æ¼”ç¤ºç³»ç»Ÿ v2.0")
    print("=" * 50)

    demos = {
        '1': ('ä¸“ä¸šå®æ—¶å¯è§†åŒ–', 'realtime_emotion_visualizer.py'),
        '2': ('3Dæ‰‹åŠ¿ä¼˜åŒ–æ¼”ç¤º', 'visualize_hand_3d_optimized.py'),
        '3': ('ä¸ªä½“åŒ–æ ¡å‡†ç³»ç»Ÿ', 'calibration_system.py'),
        '4': ('ä¿¡å·å¤„ç†å¼•æ“', 'signal_processing_engine.py'),
        '5': ('æƒ…ç»ªæ£€æµ‹å™¨æµ‹è¯•', 'emotion_state_detector.py')
    }

    print("å¯ç”¨çš„æ¼”ç¤º:")
    for key, (name, script) in demos.items():
        print(f"  {key}. {name} - {script}")

    choice = input("\nè¯·é€‰æ‹©æ¼”ç¤º (1-5): ").strip()

    if choice in demos:
        name, script = demos[choice]
        print(f"\nğŸš€ å¯åŠ¨ {name}...")
        os.system(f"python {script}")
    else:
        print("âŒ æ— æ•ˆé€‰æ‹©")

if __name__ == "__main__":
    main()
```

### run_professional_demo.py - ä¸€é”®å¯åŠ¨ä¸“ä¸šç‰ˆ
```python
#!/usr/bin/env python3
"""
ä¸€é”®å¯åŠ¨ä¸“ä¸šç‰ˆEmotionHandç³»ç»Ÿ
"""

import subprocess
import sys

def check_dependencies():
    """æ£€æŸ¥ä¾èµ–"""
    required = ['numpy', 'scipy', 'matplotlib', 'pandas']
    missing = []

    for lib in required:
        try:
            __import__(lib)
        except ImportError:
            missing.append(lib)

    if missing:
        print(f"âŒ ç¼ºå°‘ä¾èµ–: {missing}")
        print("è¯·è¿è¡Œ: pip install numpy scipy matplotlib pandas")
        return False

    return True

def main():
    print("ğŸ­ EmotionHand ä¸“ä¸šç‰ˆå¯åŠ¨å™¨")
    print("=" * 40)

    if not check_dependencies():
        sys.exit(1)

    print("âœ… ä¾èµ–æ£€æŸ¥é€šè¿‡")
    print("ğŸš€ å¯åŠ¨ä¸“ä¸šå®æ—¶å¯è§†åŒ–ç³»ç»Ÿ...")

    try:
        subprocess.run([sys.executable, 'realtime_emotion_visualizer.py'])
    except KeyboardInterrupt:
        print("\nğŸ”š ç”¨æˆ·é€€å‡º")
    except Exception as e:
        print(f"âŒ å¯åŠ¨å¤±è´¥: {e}")

if __name__ == "__main__":
    main()
```

---

## ğŸ“ˆ æ€§èƒ½åŸºå‡†ä¸ç›‘æ§

### å®æ—¶æ€§èƒ½æŒ‡æ ‡
```python
# æ€§èƒ½ç›‘æ§ç¤ºä¾‹
processor = RealTimeSignalProcessor()

# è¿è¡Œä¸€æ®µæ—¶é—´å
stats = processor.get_performance_stats()
print(f"ğŸ“Š æ€§èƒ½ç»Ÿè®¡:")
print(f"  å¤„ç†å»¶è¿Ÿ: {stats['latency_ms']:.1f}ms")
print(f"  å¤„ç†FPS: {stats['fps']:.1f}")
print(f"  ç¼“å†²åŒºçŠ¶æ€: {len(processor.emg_buffer)}/{processor.config['window']['size']}")
```

### è´¨é‡ç›‘æµ‹æŒ‡æ ‡
```python
# ä¿¡å·è´¨é‡è¯„ä¼°
quality_status = processor.get_quality_status()
print(f"ğŸ“¡ ä¿¡å·è´¨é‡:")
print(f"  çŠ¶æ€: {quality_status['status']}")
print(f"  è¯„åˆ†: {quality_status['score']:.2f}")
print(f"  æœ€è¿‘è´¨é‡: {quality_status['recent_quality']}")
```

### æƒ…ç»ªæ£€æµ‹ç»Ÿè®¡
```python
# æƒ…ç»ªçŠ¶æ€ç»Ÿè®¡
stats = detector.rule_based_detector.get_state_statistics()
print(f"ğŸ­ æƒ…ç»ªæ£€æµ‹ç»Ÿè®¡:")
print(f"  æ€»é¢„æµ‹æ•°: {stats['total_predictions']}")
print(f"  å¹³å‡ç½®ä¿¡åº¦: {stats['average_confidence']:.2f}")
print(f"  çŠ¶æ€åˆ‡æ¢ç‡: {stats['transition_rate']:.2f}")
print(f"  æœ€å¸¸è§çŠ¶æ€: {stats['most_common_state']}")
```

---

## ğŸ› ï¸ æ•…éšœæ’é™¤ä¸ç»´æŠ¤

### å¸¸è§é—®é¢˜è§£å†³

**Q: ä¿¡å·è´¨é‡å·®ï¼Ÿ**
```python
# æ£€æŸ¥ç”µæè¿æ¥
if emg_quality < 0.7:
    print("è¯·æ£€æŸ¥EMGç”µæè´´é™„")
    print("å»ºè®®: çš®è‚¤æ‰“ç£¨ + é…’ç²¾æ¸…æ´")

if gsr_connectivity == False:
    print("è¯·è°ƒæ•´GSRæŒ‡å¥—ä½ç½®")
```

**Q: å¤„ç†å»¶è¿Ÿé«˜ï¼Ÿ**
```python
# æ€§èƒ½ä¼˜åŒ–å»ºè®®
if avg_latency > 100:  # ms
    print("æ€§èƒ½ä¼˜åŒ–å»ºè®®:")
    print("1. é™ä½é‡‡æ ·ç‡: EMG 1000â†’800Hz")
    print("2. å‡å°çª—å£: 256â†’200ms")
    print("3. é™ä½ç›®æ ‡FPS: 30â†’15")
```

**Q: çŠ¶æ€è¯†åˆ«ä¸å‡†ï¼Ÿ**
```python
# é‡æ–°æ ¡å‡†å»ºè®®
if avg_confidence < 0.6:
    print("å»ºè®®é‡æ–°æ ¡å‡†:")
    print("1. è¿è¡Œ: python calibration_system.py")
    print("2. ç¡®ä¿ç¯å¢ƒå®‰é™æ— å¹²æ‰°")
    print("3. æŒ‰ç…§å¼•å¯¼å®Œæˆ60ç§’æ ¡å‡†")
```

### ç³»ç»Ÿç»´æŠ¤

**å®šæœŸç»´æŠ¤ä»»åŠ¡**:
```bash
# 1. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
find . -name "*.pyc" -delete
find . -name "__pycache__" -type d -exec rm -rf {} +

# 2. æ£€æŸ¥ä¾èµ–æ›´æ–°
pip list --outdated

# 3. å¤‡ä»½æ ¡å‡†æ¡£æ¡ˆ
cp calibration_profile_*.json backups/

# 4. æ€§èƒ½åŸºå‡†æµ‹è¯•
python -c "
from realtime_emotion_visualizer import RealtimeEmotionVisualizer
viz = RealtimeEmotionVisualizer()
viz.show_performance_stats()
"
```

---

## ğŸ“š APIå‚è€ƒ

### RealTimeSignalProcessor
```python
class RealTimeSignalProcessor:
    def __init__(self, config_path: str = 'signal_processing_config.json')
    def start(self) -> None
    def stop(self) -> None
    def add_data(self, emg_sample: List[float], gsr_sample: float, timestamp: float = None) -> None
    def process_window(self) -> Optional[Dict]
    def get_quality_status(self) -> Dict
    def get_performance_stats(self) -> Dict
```

### EmotionStateDetector
```python
class EnsembleDetector:
    def __init__(self, config: Dict)
    def predict_state(self, features: Dict[str, float], emg_features: Dict, gsr_features: Dict) -> StatePrediction

class StatePrediction:
    state: EmotionState          # æ£€æµ‹çŠ¶æ€
    confidence: float            # ç½®ä¿¡åº¦ 0-1
    raw_scores: Dict[str, float] # å„çŠ¶æ€åŸå§‹åˆ†æ•°
    reasoning: str              # æ¨ç†è¯´æ˜
    timestamp: float            # æ—¶é—´æˆ³
```

### CalibrationSystem
```python
class CalibrationSystem:
    def __init__(self, config: Dict)
    def start_calibration(self, user_id: str) -> bool
    def stop_calibration(self) -> None
    def load_calibration_profile(self, profile_path: str) -> Optional[CalibrationProfile]
    def get_available_profiles(self) -> List[str]
```

---

## ğŸ”® æ‰©å±•ä¸å¼€å‘

### æ·»åŠ æ–°çš„æƒ…ç»ªçŠ¶æ€
```python
# 1. æ›´æ–°æšä¸¾
class EmotionState(Enum):
    HAPPY = "Happy"
    SAD = "Sad"
    # ... ç°æœ‰çŠ¶æ€

# 2. æ›´æ–°é…ç½®é˜ˆå€¼
"happy": {"rms_min": 0.3, "rms_max": 0.5, "gsr_min": 0.3, "gsr_max": 0.5}

# 3. æ›´æ–°æ£€æµ‹è§„åˆ™
def _calculate_happy_score(self, rms, gsr_tonic, mdf):
    # å®ç°HappyçŠ¶æ€è¯„åˆ†é€»è¾‘
    pass
```

### é›†æˆæœºå™¨å­¦ä¹ æ¨¡å‹
```python
# 1. åˆ›å»ºMLæ£€æµ‹å™¨
class MLEmotionDetector:
    def __init__(self, model_path: str):
        self.model = self.load_model(model_path)

    def predict(self, features):
        return self.model.predict_proba(features)

# 2. é›†æˆåˆ°ç°æœ‰ç³»ç»Ÿ
ensemble_detector.ml_detectors['rf_model'] = MLEmotionDetector('rf_model.pkl')
ensemble_detector.ensemble_weights['ml_models'] = 0.3
```

### æ•°æ®è®°å½•ä¸åˆ†æ
```python
# å¯ç”¨æ•°æ®è®°å½•
config['logging']['save_features'] = True
config['logging']['save_quality'] = True

# è¿è¡Œååˆ†ææ•°æ®
import pandas as pd
df = pd.read_parquet('runs/20241022_1430/stream.parquet')
print(f"æ€»è®°å½•æ•°: {len(df)}")
print(f"å¹³å‡EMG RMS: {df['rms'].mean():.3f}")
print(f"æƒ…ç»ªåˆ†å¸ƒ:\n{df['emotion_state'].value_counts()}")
```

---

## ğŸ† ç³»ç»Ÿäº®ç‚¹

### ğŸ¯ ä¼ä¸šçº§ç‰¹æ€§
- **SOLIDåŸåˆ™**: æ¸…æ™°çš„æ¨¡å—åŒ–æ¶æ„
- **é…ç½®é©±åŠ¨**: æ‰€æœ‰å‚æ•°å¯é…ç½®
- **å¼‚å¸¸å¤„ç†**: å®Œæ•´çš„é”™è¯¯æ¢å¤æœºåˆ¶
- **æ€§èƒ½ç›‘æ§**: å®æ—¶FPSå’Œå»¶è¿Ÿè¿½è¸ª
- **æ—¥å¿—ç³»ç»Ÿ**: åˆ†çº§æ—¥å¿—è®°å½•

### âš¡ æ€§èƒ½ä¼˜åŠ¿
- **ä½å»¶è¿Ÿ**: <100msç«¯åˆ°ç«¯å¤„ç†
- **é«˜å¸§ç‡**: 15-30 FPSæµç•…æ¸²æŸ“
- **å†…å­˜ä¼˜åŒ–**: <500MBå†…å­˜å ç”¨
- **CPUæ•ˆç‡**: <30%å•æ ¸ä½¿ç”¨ç‡

### ğŸ”¬ ä¸“ä¸šå¤„ç†
- **EMGä¸“ä¸šå¤„ç†**: å¸¦é€šæ»¤æ³¢ + å·¥é¢‘é™·æ³¢ + ç‰¹å¾æå–
- **GSRä¸“ä¸šåˆ†æ**: åŸºè°ƒ/ååº”åˆ†ç¦» + SCRæ£€æµ‹
- **è´¨é‡ç›‘æµ‹**: SNRè¯„ä¼° + å¤¹é¡¶æ£€æµ‹ + ä¼ªè¿¹è¯†åˆ«
- **ä¸ªä½“åŒ–æ ¡å‡†**: åˆ†ä½å½’ä¸€åŒ– + ä¸ªäººåŸºçº¿

### ğŸ¨ å¯è§†åŒ–æ•ˆæœ
- **éœ‡æ’¼3Dæ¨¡å‹**: åŠé€æ˜æ‰‹æŒ + åŠ¨æ€æ‰‹æŒ‡
- **å®æ—¶æ•°æ®é©±åŠ¨**: EMG/GSRå®æ—¶å¯è§†åŒ–
- **æ™ºèƒ½é¢œè‰²æ˜ å°„**: çŠ¶æ€é©±åŠ¨çš„è§†è§‰åé¦ˆ
- **ä¸“ä¸šé¢æ¿**: è´¨é‡ç›‘æµ‹ + æ€§èƒ½ç»Ÿè®¡

---

## ğŸ‰ æ€»ç»“

EmotionHand v2.0 æ˜¯ä¸€å¥—å®Œæ•´çš„ä¼ä¸šçº§EMG+GSRä¿¡å·å¤„ç†ä¸å¯è§†åŒ–ç³»ç»Ÿï¼Œå®ç°äº†ï¼š

âœ… **ä¸“ä¸šé¢„å¤„ç†é“ä¸‰è§’**: ä¿¡å·â†’æ—¶é—´çª—â†’å½’ä¸€åŒ–
âœ… **ä¼ä¸šçº§æ¶æ„**: SOLIDåŸåˆ™ï¼Œé…ç½®é©±åŠ¨ï¼Œå¼‚å¸¸å¤„ç†
âœ… **å®æ—¶æ€§èƒ½**: <100mså»¶è¿Ÿï¼Œ15-30 FPSæ¸²æŸ“
âœ… **ä¸ªä½“åŒ–é€‚é…**: 60ç§’æ ¡å‡†ï¼Œåˆ†ä½å½’ä¸€åŒ–
âœ… **æ™ºèƒ½æ£€æµ‹**: è§„åˆ™åŸºçº¿ + MLæ‰©å±•æ¥å£
âœ… **éœ‡æ’¼å¯è§†åŒ–**: 3Dæ‰‹åŠ¿ + å®æ—¶ç›‘æµ‹é¢æ¿
âœ… **å®Œæ•´æ–‡æ¡£**: APIå‚è€ƒï¼Œæ•…éšœæ’é™¤ï¼Œæ‰©å±•æŒ‡å—

ç°åœ¨æ‚¨å¯ä»¥ï¼š
ğŸš€ **ä¸€é”®å¯åŠ¨**: `python realtime_emotion_visualizer.py`
ğŸ”§ **å¿«é€Ÿæ ¡å‡†**: `python calibration_system.py`
ğŸ“Š **æ€§èƒ½ç›‘æ§**: å®æ—¶FPS/å»¶è¿Ÿ/è´¨é‡ç›‘æµ‹
ğŸ¯ **å³æ’å³ç”¨**: æ”¯æŒçœŸå®ç¡¬ä»¶æˆ–æ¨¡æ‹Ÿæ•°æ®

ç³»ç»Ÿå·²å®Œå…¨å°±ç»ªï¼Œä¸ºæ‚¨çš„æƒ…ç»ªæ‰‹åŠ¿è¯†åˆ«é¡¹ç›®æä¾›åšå®çš„æŠ€æœ¯åŸºç¡€ï¼ğŸš€