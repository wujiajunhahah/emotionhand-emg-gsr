#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
EmotionHand å®åœ°è¿è¡Œè„šæœ¬
æ•´åˆäº†zcfé¡¹ç›®çš„ä¸“ä¸šä¿¡å·å¤„ç†å¼•æ“
"""

import sys
import os
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
import tkinter as tk
from tkinter import ttk, messagebox
import threading
import time
from collections import deque
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®matplotlibå­—ä½“
import matplotlib
matplotlib.rcParams['font.family'] = 'DejaVu Sans'
matplotlib.rcParams['axes.unicode_minus'] = False

# æ·»åŠ zcfé¡¹ç›®è·¯å¾„
zcf_paths = [
    "/Users/wujiajun/Downloads/zcf/EmotionHand_GitHub",
    "/Users/wujiajun/Downloads/zcf/gesture",
    "/Users/wujiajun/Downloads/zcf/GestureSense_Complete_Project"
]

for path in zcf_paths:
    if os.path.exists(path):
        sys.path.insert(0, path)

# å¯¼å…¥ä¸“ä¸šä¿¡å·å¤„ç†å¼•æ“
try:
    from signal_processing_engine import RealTimeSignalProcessor
    PROFESSIONAL_ENGINE_AVAILABLE = True
    print("âœ… æˆåŠŸåŠ è½½ä¼ä¸šçº§ä¿¡å·å¤„ç†å¼•æ“")
except ImportError as e:
    print(f"âš ï¸ ä¼ä¸šçº§ä¿¡å·å¤„ç†å¼•æ“åŠ è½½å¤±è´¥: {e}")
    PROFESSIONAL_ENGINE_AVAILABLE = False

# å°è¯•å¯¼å…¥å…¶ä»–ç»„ä»¶
try:
    from emotion_state_detector import EnsembleDetector
    ENSEMBLE_DETECTOR_AVAILABLE = True
    print("âœ… æˆåŠŸåŠ è½½é›†æˆæƒ…ç»ªæ£€æµ‹å™¨")
except ImportError as e:
    print(f"âš ï¸ é›†æˆæƒ…ç»ªæ£€æµ‹å™¨åŠ è½½å¤±è´¥: {e}")
    ENSEMBLE_DETECTOR_AVAILABLE = False

try:
    from calibration_system import CalibrationSystem
    CALIBRATION_AVAILABLE = True
    print("âœ… æˆåŠŸåŠ è½½æ ¡å‡†ç³»ç»Ÿ")
except ImportError as e:
    print(f"âš ï¸ æ ¡å‡†ç³»ç»ŸåŠ è½½å¤±è´¥: {e}")
    CALIBRATION_AVAILABLE = False

class FieldEmotionHand:
    """å®åœ°ç‰ˆEmotionHand"""

    def __init__(self):
        # åˆ›å»ºä¸»çª—å£
        self.root = tk.Tk()
        self.root.title("EmotionHand å®åœ°è¿è¡Œç‰ˆ - ä¸“ä¸šEMG+GSRæƒ…ç»ªè¯†åˆ«")
        self.root.geometry("1400x800")

        # æƒ…ç»ªçŠ¶æ€å®šä¹‰
        self.emotion_states = {
            'Neutral': {'color': '#808080', 'emoji': 'ğŸ˜', 'description': 'å¹³é™'},
            'Happy': {'color': '#FFD700', 'emoji': 'ğŸ˜Š', 'description': 'å¼€å¿ƒ'},
            'Stress': {'color': '#FF6B6B', 'emoji': 'ğŸ˜°', 'description': 'å‹åŠ›'},
            'Focus': {'color': '#4ECDC4', 'emoji': 'ğŸ¯', 'description': 'ä¸“æ³¨'},
            'Excited': {'color': '#FF1744', 'emoji': 'ğŸ¤©', 'description': 'å…´å¥‹'}
        }

        # å½“å‰çŠ¶æ€
        self.current_emotion = 'Neutral'
        self.emotion_confidence = 0.5

        # æ•°æ®å­˜å‚¨
        self.emg_data = deque(maxlen=500)
        self.gsr_data = deque(maxlen=500)
        self.emotion_history = deque(maxlen=100)
        self.time_stamps = deque(maxlen=500)

        # åˆå§‹åŒ–ç»„ä»¶
        self.init_components()

        # åŠ¨ç”»æ§åˆ¶
        self.animation = None
        self.is_running = False
        self.start_time = time.time()

        # è®¾ç½®ç•Œé¢
        self.setup_ui()

    def init_components(self):
        """åˆå§‹åŒ–ç»„ä»¶"""
        # ä¿¡å·å¤„ç†å¼•æ“
        self.signal_engine = None
        if PROFESSIONAL_ENGINE_AVAILABLE:
            try:
                config_path = "/Users/wujiajun/Downloads/zcf/EmotionHand_GitHub/signal_processing_config.json"
                if not os.path.exists(config_path):
                    config_path = None

                self.signal_engine = RealTimeSignalProcessor(config_path)
                self.signal_engine.start()
                print("âœ… ä¿¡å·å¤„ç†å¼•æ“åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                print(f"âŒ ä¿¡å·å¤„ç†å¼•æ“åˆå§‹åŒ–å¤±è´¥: {e}")

        # æƒ…ç»ªæ£€æµ‹å™¨
        self.emotion_detector = None
        if ENSEMBLE_DETECTOR_AVAILABLE:
            try:
                self.emotion_detector = EnsembleDetector()
                print("âœ… æƒ…ç»ªæ£€æµ‹å™¨åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                print(f"âŒ æƒ…ç»ªæ£€æµ‹å™¨åˆå§‹åŒ–å¤±è´¥: {e}")

        # æ ¡å‡†ç³»ç»Ÿ
        self.calibration_system = None
        if CALIBRATION_AVAILABLE:
            try:
                self.calibration_system = CalibrationSystem()
                print("âœ… æ ¡å‡†ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                print(f"âŒ æ ¡å‡†ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")

    def setup_ui(self):
        """è®¾ç½®ç”¨æˆ·ç•Œé¢"""
        # ä¸»æ¡†æ¶
        main_frame = ttk.Frame(self.root)
        main_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)

        # æ ‡é¢˜
        title_label = ttk.Label(main_frame,
                               text="EmotionHand å®åœ°è¿è¡Œç‰ˆ - ä¸“ä¸šEMG+GSRæƒ…ç»ªè¯†åˆ«ç³»ç»Ÿ",
                               font=('Arial', 16, 'bold'))
        title_label.pack(pady=5)

        # ç³»ç»ŸçŠ¶æ€
        status_frame = ttk.LabelFrame(main_frame, text="ç³»ç»ŸçŠ¶æ€", padding=10)
        status_frame.pack(fill=tk.X, pady=5)

        # åˆ›å»ºçŠ¶æ€æ˜¾ç¤º
        status_info = []
        if PROFESSIONAL_ENGINE_AVAILABLE:
            status_info.append("âœ… ä¼ä¸šçº§ä¿¡å·å¤„ç†å¼•æ“")
        else:
            status_info.append("âš ï¸ ç®€åŒ–ä¿¡å·å¤„ç†")

        if ENSEMBLE_DETECTOR_AVAILABLE:
            status_info.append("âœ… é›†æˆæƒ…ç»ªæ£€æµ‹å™¨")
        else:
            status_info.append("âš ï¸ åŸºç¡€æƒ…ç»ªæ£€æµ‹")

        if CALIBRATION_AVAILABLE:
            status_info.append("âœ… ä¸“ä¸šæ ¡å‡†ç³»ç»Ÿ")
        else:
            status_info.append("âš ï¸ åŸºç¡€æ ¡å‡†")

        ttk.Label(status_frame, text=" | ".join(status_info),
                 font=('Arial', 10)).pack()

        # å½“å‰çŠ¶æ€æ¡†æ¶
        current_frame = ttk.LabelFrame(main_frame, text="å½“å‰çŠ¶æ€", padding=10)
        current_frame.pack(fill=tk.X, pady=5)

        self.emotion_label = ttk.Label(current_frame,
                                      text=f"ğŸ˜ å¹³é™ - ç½®ä¿¡åº¦: 0.50",
                                      font=('Arial', 14, 'bold'))
        self.emotion_label.pack()

        self.quality_label = ttk.Label(current_frame,
                                       text="ä¿¡å·è´¨é‡: æ£€æµ‹ä¸­...",
                                       font=('Arial', 11))
        self.quality_label.pack()

        # åˆ›å»ºå›¾è¡¨
        self.create_plots(main_frame)

        # æ§åˆ¶é¢æ¿
        self.create_control_panel(main_frame)

    def create_plots(self, parent):
        """åˆ›å»ºå›¾è¡¨"""
        # åˆ›å»ºmatplotlibå›¾å½¢
        self.fig = plt.figure(figsize=(14, 6), facecolor='white')

        # EMGä¿¡å·å›¾
        self.ax_emg = self.fig.add_subplot(131)
        self.ax_emg.set_title('EMGä¿¡å·', fontsize=12, fontweight='bold')
        self.ax_emg.set_xlabel('æ—¶é—´ (s)')
        self.ax_emg.set_ylabel('å¹…å€¼')
        self.ax_emg.grid(True, alpha=0.3)
        self.ax_emg.set_ylim(-1, 1)

        # GSRä¿¡å·å›¾
        self.ax_gsr = self.fig.add_subplot(132)
        self.ax_gsr.set_title('GSRä¿¡å·', fontsize=12, fontweight='bold')
        self.ax_gsr.set_xlabel('æ—¶é—´ (s)')
        self.ax_gsr.set_ylabel('ç”µå¯¼ (Î¼S)')
        self.ax_gsr.grid(True, alpha=0.3)
        self.ax_gsr.set_ylim(0, 5)

        # æƒ…ç»ªçŠ¶æ€å›¾
        self.ax_emotion = self.fig.add_subplot(133)
        self.ax_emotion.set_title('æƒ…ç»ªçŠ¶æ€æ—¶é—´çº¿', fontsize=12, fontweight='bold')
        self.ax_emotion.set_xlabel('æ—¶é—´ (s)')
        self.ax_emotion.set_ylabel('æƒ…ç»ªçŠ¶æ€')
        self.ax_emotion.set_ylim(-0.5, len(self.emotion_states) - 0.5)
        self.ax_emotion.set_yticks(range(len(self.emotion_states)))
        self.ax_emotion.set_yticklabels(list(self.emotion_states.keys()))
        self.ax_emotion.grid(True, alpha=0.3)

        # åµŒå…¥åˆ°tkinter
        self.canvas = FigureCanvasTkAgg(self.fig, parent)
        self.canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)

        self.fig.tight_layout()

    def create_control_panel(self, parent):
        """åˆ›å»ºæ§åˆ¶é¢æ¿"""
        control_frame = ttk.Frame(parent)
        control_frame.pack(fill=tk.X, pady=10)

        # ä¸»è¦æ§åˆ¶æŒ‰é’®
        self.start_btn = ttk.Button(control_frame, text="ğŸš€ å¼€å§‹ç›‘æµ‹",
                                   command=self.start_monitoring)
        self.start_btn.pack(side=tk.LEFT, padx=5)

        self.stop_btn = ttk.Button(control_frame, text="â¹ï¸ åœæ­¢ç›‘æµ‹",
                                  command=self.stop_monitoring,
                                  state=tk.DISABLED)
        self.stop_btn.pack(side=tk.LEFT, padx=5)

        self.calibrate_btn = ttk.Button(control_frame, text="ğŸ¯ æ ¡å‡†",
                                       command=self.start_calibration)
        self.calibrate_btn.pack(side=tk.LEFT, padx=5)

        # åŠŸèƒ½æŒ‰é’®
        ttk.Button(control_frame, text="ğŸ“Š ä¿å­˜æ•°æ®",
                  command=self.save_data).pack(side=tk.LEFT, padx=5)

        ttk.Button(control_frame, text="ğŸ”„ é‡ç½®",
                  command=self.reset_system).pack(side=tk.LEFT, padx=5)

        # æ¨¡å¼åˆ‡æ¢
        ttk.Label(control_frame, text="è¿è¡Œæ¨¡å¼:").pack(side=tk.LEFT, padx=(20, 5))
        self.mode_var = tk.StringVar(value="æ¼”ç¤ºæ¨¡å¼")
        mode_combo = ttk.Combobox(control_frame, textvariable=self.mode_var,
                                   values=["æ¼”ç¤ºæ¨¡å¼", "å®æ—¶æ¨¡å¼"], state="readonly", width=10)
        mode_combo.pack(side=tk.LEFT, padx=5)

    def generate_realistic_demo_data(self):
        """ç”ŸæˆçœŸå®çš„æ¼”ç¤ºæ•°æ®"""
        current_time = time.time() - self.start_time

        # æ ¹æ®æƒ…ç»ªçŠ¶æ€ç”Ÿæˆä¸åŒçš„EMGä¿¡å·æ¨¡å¼
        emg_channels = []
        for ch in range(8):
            # åŸºç¡€ä¿¡å·
            base_freq = 10 + ch * 2
            signal = 0.1 * np.sin(2 * np.pi * base_freq * current_time)

            # æ·»åŠ æƒ…ç»ªç‰¹å¾
            if self.current_emotion == 'Stress':
                # å‹åŠ›ï¼šé«˜é¢‘å™ªå£°å¢åŠ 
                signal += 0.2 * np.random.randn() + 0.1 * np.sin(2 * np.pi * 50 * current_time)
            elif self.current_emotion == 'Happy':
                # å¼€å¿ƒï¼šä¸­ç­‰é¢‘ç‡è§„å¾‹ä¿¡å·
                signal += 0.15 * np.sin(2 * np.pi * 20 * current_time)
            elif self.current_emotion == 'Focus':
                # ä¸“æ³¨ï¼šä½é¢‘ç¨³å®šä¿¡å·
                signal *= 0.7
                signal += 0.05 * np.sin(2 * np.pi * 5 * current_time)
            elif self.current_emotion == 'Excited':
                # å…´å¥‹ï¼šå¤šé¢‘ç‡æ··åˆ
                signal += 0.1 * np.sin(2 * np.pi * 30 * current_time)
                signal += 0.08 * np.sin(2 * np.pi * 60 * current_time)

            # æ·»åŠ å™ªå£°
            signal += 0.02 * np.random.randn()
            emg_channels.append(np.clip(signal, -1, 1))

        # ç”ŸæˆGSRä¿¡å·
        base_gsr = 2.0 + 0.3 * np.sin(2 * np.pi * 0.1 * current_time)

        if self.current_emotion == 'Stress':
            base_gsr += 0.4  # å‹åŠ›æ—¶çš®ç”µå¢å¼º
        elif self.current_emotion == 'Excited':
            base_gsr += 0.2 + 0.1 * np.sin(2 * np.pi * 0.5 * current_time)

        gsr_value = max(0.1, base_gsr + 0.05 * np.random.randn())

        return emg_channels, gsr_value

    def get_demo_emotion(self):
        """è·å–æ¼”ç¤ºæƒ…ç»ªçŠ¶æ€"""
        current_time = time.time() - self.start_time
        cycle_time = 25  # 25ç§’ä¸€ä¸ªå‘¨æœŸ
        phase = (current_time % cycle_time) / cycle_time

        if phase < 0.2:
            return 'Neutral'
        elif phase < 0.4:
            return 'Focus'
        elif phase < 0.6:
            return 'Happy'
        elif phase < 0.8:
            return 'Excited'
        else:
            return 'Stress'

    def process_data(self):
        """å¤„ç†æ•°æ®"""
        is_demo_mode = self.mode_var.get() == "æ¼”ç¤ºæ¨¡å¼"

        if is_demo_mode:
            # æ¼”ç¤ºæ¨¡å¼
            self.current_emotion = self.get_demo_emotion()
            emg_data, gsr_data = self.generate_realistic_demo_data()
            quality_score = np.random.uniform(0.7, 0.95)
            processing_time = np.random.uniform(0.005, 0.015)

            return {
                'emg_data': emg_data,
                'gsr_data': gsr_data,
                'emotion': self.current_emotion,
                'confidence': 0.7 + 0.2 * np.random.random(),
                'quality_score': quality_score,
                'processing_time': processing_time
            }

        # å®æ—¶æ¨¡å¼
        if self.signal_engine:
            try:
                result = self.signal_engine.process_window()
                if result:
                    # æ£€æµ‹æƒ…ç»ª
                    emotion = self.detect_emotion_from_features(result['normalized_features'])

                    return {
                        'emg_data': [result['emg_features']['rms']] * 8,  # ç®€åŒ–å¤„ç†
                        'gsr_data': result['gsr_features']['tonic'],
                        'emotion': emotion,
                        'confidence': 0.8,
                        'quality_score': result['quality']['overall'],
                        'processing_time': result['processing_time'],
                        'features': result['normalized_features']
                    }
            except Exception as e:
                print(f"æ•°æ®å¤„ç†é”™è¯¯: {e}")

        return None

    def detect_emotion_from_features(self, features):
        """ä»ç‰¹å¾æ£€æµ‹æƒ…ç»ª"""
        # ç®€åŒ–çš„æƒ…ç»ªæ£€æµ‹é€»è¾‘
        if not features:
            return 'Neutral'

        rms = features.get('rms', 0.5)
        gsr_tonic = features.get('gsr_tonic', 0.5)

        if rms > 0.7 and gsr_tonic > 0.7:
            return 'Stress'
        elif rms > 0.6 and gsr_tonic < 0.4:
            return 'Focus'
        elif rms > 0.5 and 0.3 < gsr_tonic < 0.7:
            return 'Happy'
        elif rms > 0.8:
            return 'Excited'
        else:
            return 'Neutral'

    def update_plots(self, frame):
        """æ›´æ–°å›¾è¡¨"""
        if not self.is_running:
            return

        # å¤„ç†æ•°æ®
        result = self.process_data()
        if not result:
            return

        # æ›´æ–°çŠ¶æ€
        self.current_emotion = result['emotion']
        self.emotion_confidence = result['confidence']

        # å­˜å‚¨æ•°æ®
        current_time = time.time() - self.start_time
        self.time_stamps.append(current_time)

        if result['emg_data']:
            self.emg_data.append(np.mean(result['emg_data']))
        self.gsr_data.append(result['gsr_data'])
        self.emotion_history.append(result['emotion'])

        # æ›´æ–°å›¾è¡¨
        self.update_emg_plot()
        self.update_gsr_plot()
        self.update_emotion_plot()

        # æ›´æ–°çŠ¶æ€æ˜¾ç¤º
        self.update_status_display(result)

        # åˆ·æ–°ç”»å¸ƒ
        self.canvas.draw()

    def update_emg_plot(self):
        """æ›´æ–°EMGå›¾"""
        self.ax_emg.clear()
        self.ax_emg.set_title('EMGä¿¡å·', fontsize=12, fontweight='bold')
        self.ax_emg.set_xlabel('æ—¶é—´ (s)')
        self.ax_emg.set_ylabel('å¹…å€¼')
        self.ax_emg.grid(True, alpha=0.3)

        if len(self.emg_data) > 0:
            times = list(self.time_stamps)[-len(self.emg_data):]
            self.ax_emg.plot(times, list(self.emg_data),
                           color=self.emotion_states[self.current_emotion]['color'],
                           linewidth=1.5, alpha=0.8)
            self.ax_emg.set_ylim(-1, 1)

    def update_gsr_plot(self):
        """æ›´æ–°GSRå›¾"""
        self.ax_gsr.clear()
        self.ax_gsr.set_title('GSRä¿¡å·', fontsize=12, fontweight='bold')
        self.ax_gsr.set_xlabel('æ—¶é—´ (s)')
        self.ax_gsr.set_ylabel('ç”µå¯¼ (Î¼S)')
        self.ax_gsr.grid(True, alpha=0.3)

        if len(self.gsr_data) > 0:
            times = list(self.time_stamps)[-len(self.gsr_data):]
            self.ax_gsr.plot(times, list(self.gsr_data),
                           color=self.emotion_states[self.current_emotion]['color'],
                           linewidth=1.5, alpha=0.8)
            self.ax_gsr.set_ylim(0, 5)

    def update_emotion_plot(self):
        """æ›´æ–°æƒ…ç»ªçŠ¶æ€å›¾"""
        self.ax_emotion.clear()
        self.ax_emotion.set_title('æƒ…ç»ªçŠ¶æ€æ—¶é—´çº¿', fontsize=12, fontweight='bold')
        self.ax_emotion.set_xlabel('æ—¶é—´ (s)')
        self.ax_emotion.set_ylabel('æƒ…ç»ªçŠ¶æ€')
        self.ax_emotion.set_ylim(-0.5, len(self.emotion_states) - 0.5)
        self.ax_emotion.set_yticks(range(len(self.emotion_states)))
        self.ax_emotion.set_yticklabels(list(self.emotion_states.keys()))
        self.ax_emotion.grid(True, alpha=0.3)

        if len(self.emotion_history) > 0:
            times = list(self.time_stamps)[-len(self.emotion_history):]
            emotion_values = []
            emotion_colors = []

            for emotion in self.emotion_history:
                if emotion in self.emotion_states:
                    idx = list(self.emotion_states.keys()).index(emotion)
                    emotion_values.append(idx)
                    emotion_colors.append(self.emotion_states[emotion]['color'])

            self.ax_emotion.scatter(times, emotion_values, c=emotion_colors, s=20, alpha=0.7)

    def update_status_display(self, result):
        """æ›´æ–°çŠ¶æ€æ˜¾ç¤º"""
        emotion_info = self.emotion_states[self.current_emotion]
        self.emotion_label.config(
            text=f"{emotion_info['emoji']} {emotion_info['description']} - ç½®ä¿¡åº¦: {result['confidence']:.2f}"
        )

        quality_score = result.get('quality_score', 0.5)
        if quality_score >= 0.8:
            quality_text = "ä¼˜ç§€"
            color = "green"
        elif quality_score >= 0.6:
            quality_text = "è‰¯å¥½"
            color = "blue"
        else:
            quality_text = "ä¸€èˆ¬"
            color = "orange"

        self.quality_label.config(
            text=f"ä¿¡å·è´¨é‡: {quality_text} ({quality_score:.2f}) | å»¶è¿Ÿ: {result['processing_time']*1000:.1f}ms",
            foreground=color
        )

    def start_monitoring(self):
        """å¼€å§‹ç›‘æµ‹"""
        if not self.is_running:
            self.is_running = True
            self.start_time = time.time()
            self.start_btn.config(state=tk.DISABLED)
            self.stop_btn.config(state=tk.NORMAL)

            # é‡å¯ä¿¡å·å¼•æ“
            if self.signal_engine:
                self.signal_engine.start()

            # åˆ›å»ºåŠ¨ç”»
            from matplotlib.animation import FuncAnimation
            self.animation = FuncAnimation(self.fig, self.update_plots,
                                         interval=100, blit=False)
            self.canvas.draw()

            print(f"ğŸš€ å¼€å§‹ç›‘æµ‹ - æ¨¡å¼: {self.mode_var.get()}")

    def stop_monitoring(self):
        """åœæ­¢ç›‘æµ‹"""
        if self.is_running:
            self.is_running = False
            self.start_btn.config(state=tk.NORMAL)
            self.stop_btn.config(state=tk.DISABLED)

            if self.animation is not None:
                self.animation.event_source.stop()
                self.animation = None

            if self.signal_engine:
                self.signal_engine.stop()

            print("â¹ï¸ åœæ­¢ç›‘æµ‹")

    def start_calibration(self):
        """å¼€å§‹æ ¡å‡†"""
        if self.calibration_system:
            self.calibrate_btn.config(state=tk.DISABLED)
            threading.Thread(target=self._calibration_thread, daemon=True).start()
        else:
            messagebox.showinfo("æç¤º", "æ ¡å‡†ç³»ç»Ÿä¸å¯ç”¨")

    def _calibration_thread(self):
        """æ ¡å‡†çº¿ç¨‹"""
        try:
            messagebox.showinfo("æ ¡å‡†", "å¼€å§‹60ç§’æ ¡å‡†ç¨‹åº...\nè¯·ä¿æŒé™æ­¢30ç§’ï¼Œç„¶åè½»æ¡30ç§’")
            # è¿™é‡Œå¯ä»¥è°ƒç”¨å®é™…çš„æ ¡å‡†ç¨‹åº
            time.sleep(2)  # æ¨¡æ‹Ÿæ ¡å‡†
            messagebox.showinfo("å®Œæˆ", "æ ¡å‡†å®Œæˆï¼")
        except Exception as e:
            messagebox.showerror("é”™è¯¯", f"æ ¡å‡†å¤±è´¥: {e}")
        finally:
            self.calibrate_btn.config(state=tk.NORMAL)

    def save_data(self):
        """ä¿å­˜æ•°æ®"""
        try:
            import json
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            filename = f"emotionhand_field_data_{timestamp}.json"

            data = {
                'timestamp': timestamp,
                'mode': self.mode_var.get(),
                'duration': time.time() - self.start_time if self.is_running else 0,
                'emotion_history': list(self.emotion_history),
                'system_info': {
                    'professional_engine': PROFESSIONAL_ENGINE_AVAILABLE,
                    'ensemble_detector': ENSEMBLE_DETECTOR_AVAILABLE,
                    'calibration_system': CALIBRATION_AVAILABLE
                }
            }

            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)

            messagebox.showinfo("æˆåŠŸ", f"æ•°æ®å·²ä¿å­˜åˆ°: {filename}")
        except Exception as e:
            messagebox.showerror("é”™è¯¯", f"ä¿å­˜å¤±è´¥: {e}")

    def reset_system(self):
        """é‡ç½®ç³»ç»Ÿ"""
        if messagebox.askyesno("ç¡®è®¤", "ç¡®å®šè¦é‡ç½®ç³»ç»Ÿå—ï¼Ÿ"):
            # æ¸…ç©ºæ•°æ®
            self.emg_data.clear()
            self.gsr_data.clear()
            self.emotion_history.clear()
            self.time_stamps.clear()

            # é‡ç½®çŠ¶æ€
            self.current_emotion = 'Neutral'
            self.emotion_confidence = 0.5
            self.start_time = time.time()

            messagebox.showinfo("å®Œæˆ", "ç³»ç»Ÿå·²é‡ç½®")

    def run(self):
        """è¿è¡Œåº”ç”¨"""
        def on_closing():
            if self.is_running:
                self.stop_monitoring()

            if self.signal_engine:
                self.signal_engine.stop()

            self.root.quit()
            self.root.destroy()

        self.root.protocol("WM_DELETE_WINDOW", on_closing)

        print("ğŸš€ EmotionHand å®åœ°è¿è¡Œç‰ˆå¯åŠ¨æˆåŠŸ!")
        print("ğŸ“‹ ç³»ç»Ÿç»„ä»¶:")
        print(f"   â€¢ ä¿¡å·å¤„ç†å¼•æ“: {'ä¼ä¸šçº§' if PROFESSIONAL_ENGINE_AVAILABLE else 'ç®€åŒ–ç‰ˆ'}")
        print(f"   â€¢ æƒ…ç»ªæ£€æµ‹å™¨: {'é›†æˆç‰ˆ' if ENSEMBLE_DETECTOR_AVAILABLE else 'åŸºç¡€ç‰ˆ'}")
        print(f"   â€¢ æ ¡å‡†ç³»ç»Ÿ: {'ä¸“ä¸šç‰ˆ' if CALIBRATION_AVAILABLE else 'åŸºç¡€ç‰ˆ'}")
        print("\nğŸ® ä½¿ç”¨è¯´æ˜:")
        print("   â€¢ é€‰æ‹©è¿è¡Œæ¨¡å¼ï¼ˆæ¼”ç¤º/å®æ—¶ï¼‰")
        print("   â€¢ ç‚¹å‡»'å¼€å§‹ç›‘æµ‹'å¯åŠ¨ç³»ç»Ÿ")
        print("   â€¢ è§‚å¯Ÿä¿¡å·æ³¢å½¢å’Œæƒ…ç»ªå˜åŒ–")
        print("   â€¢ å¯è¿›è¡Œæ ¡å‡†å’Œä¿å­˜æ•°æ®")

        self.root.mainloop()

if __name__ == "__main__":
    app = FieldEmotionHand()
    app.run()