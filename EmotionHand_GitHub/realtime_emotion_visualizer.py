#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
EmotionHand å®æ—¶æƒ…ç»ªå¯è§†åŒ–ç³»ç»Ÿ
Real-time Emotion Visualization with Professional Signal Processing

é›†æˆä¸“ä¸šçº§ä¿¡å·å¤„ç†çš„å®æ—¶å¯è§†åŒ–ç³»ç»Ÿï¼š
â€¢ ä¼ä¸šçº§ä¿¡å·å¤„ç†å¼•æ“
â€¢ ä¸ªä½“åŒ–æ ¡å‡†ç³»ç»Ÿ
â€¢ ä½å»¶è¿Ÿæƒ…ç»ªçŠ¶æ€æ£€æµ‹
â€¢ 3Dæ‰‹åŠ¿å¯è§†åŒ– + è´¨é‡ç›‘æµ‹é¢æ¿

Author: EmotionHand Team
Version: 2.0.0
"""

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from matplotlib.animation import FuncAnimation
import time
import json
import logging
import threading
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from collections import deque
import queue

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from signal_processing_engine import RealTimeSignalProcessor, SignalQuality
from calibration_system import CalibrationSystem
from emotion_state_detector import EnsembleDetector, EmotionState

# è®¾ç½®ä¸­æ–‡å­—ä½“å’Œæ ·å¼
plt.rcParams['font.sans-serif'] = ['SimHei', 'PingFang SC', 'Microsoft YaHei', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False
plt.style.use('seaborn-v0_8-darkgrid')

logger = logging.getLogger(__name__)


class EmotionVisualizationPanel:
    """æƒ…ç»ªçŠ¶æ€å¯è§†åŒ–é¢æ¿"""

    def __init__(self, fig, ax_position):
        self.fig = fig
        self.ax = fig.add_axes(ax_position)
        self.ax.set_title('æƒ…ç»ªçŠ¶æ€ç›‘æµ‹', fontsize=14, fontweight='bold', pad=20)

        # æƒ…ç»ªçŠ¶æ€é…ç½®
        self.emotion_config = {
            'Relaxed': {'color': '#3498db', 'y': 0.8},
            'Focused': {'color': '#2ecc71', 'y': 0.6},
            'Stressed': {'color': '#e74c3c', 'y': 0.4},
            'Fatigued': {'color': '#f39c12', 'y': 0.2}
        }

        # å†å²æ•°æ®
        self.state_history = deque(maxlen=50)
        self.confidence_history = deque(maxlen=50)

        self._setup_axes()

    def _setup_axes(self):
        """è®¾ç½®åæ ‡è½´"""
        self.ax.set_xlim(0, 50)
        self.ax.set_ylim(0, 1)
        self.ax.set_xlabel('æ—¶é—´ (æ ·æœ¬)', fontsize=10)
        self.ax.set_ylabel('ç½®ä¿¡åº¦', fontsize=10)
        self.ax.grid(True, alpha=0.3)

        # Yè½´æ ‡ç­¾
        self.ax.set_yticks([config['y'] for config in self.emotion_config.values()])
        self.ax.set_yticklabels(list(self.emotion_config.keys()))

    def update(self, prediction, quality_status):
        """æ›´æ–°æƒ…ç»ªçŠ¶æ€é¢æ¿"""
        # æ·»åŠ åˆ°å†å²è®°å½•
        self.state_history.append(prediction.state.value)
        self.confidence_history.append(prediction.confidence)

        # æ¸…é™¤å¹¶é‡ç»˜
        self.ax.clear()
        self._setup_axes()

        if len(self.state_history) > 1:
            # ç»˜åˆ¶çŠ¶æ€æ—¶é—´çº¿
            x_data = list(range(len(self.state_history)))
            y_data = [self.emotion_config[state]['y'] for state in self.state_history]

            # ç»˜åˆ¶è¿çº¿
            for i in range(len(x_data) - 1):
                self.ax.plot(x_data[i:i+2], y_data[i:i+2],
                           color=self.emotion_config[self.state_history[i]]['color'],
                           alpha=0.7, linewidth=3)

            # ç»˜åˆ¶æ•°æ®ç‚¹ï¼ˆå¤§å°åŸºäºç½®ä¿¡åº¦ï¼‰
            for i, (x, y, conf, state) in enumerate(zip(x_data, y_data, self.confidence_history, self.state_history)):
                self.ax.scatter(x, y, s=50 + conf * 100,
                              color=self.emotion_config[state]['color'],
                              alpha=0.8, edgecolors='white', linewidth=1)

            # æ ‡è®°å½“å‰çŠ¶æ€
            current_color = self.emotion_config[prediction.state.value]['color']
            self.ax.scatter(x_data[-1], y_data[-1], s=200,
                          color=current_color, alpha=1.0,
                          edgecolors='white', linewidth=3, marker='o')

        # æ˜¾ç¤ºå½“å‰çŠ¶æ€ä¿¡æ¯
        info_text = (f"å½“å‰çŠ¶æ€: {prediction.state.value}\n"
                    f"ç½®ä¿¡åº¦: {prediction.confidence:.2f}\n"
                    f"æ¨ç†: {prediction.reasoning}")

        self.ax.text(0.02, 0.98, info_text, transform=self.ax.transAxes,
                    fontsize=9, verticalalignment='top',
                    bbox=dict(boxstyle='round,pad=0.5', facecolor='white', alpha=0.9))

        # è´¨é‡çŠ¶æ€æŒ‡ç¤ºå™¨
        quality_color = {'excellent': '#2ecc71', 'good': '#f39c12',
                        'poor': '#e67e22', 'bad': '#e74c3c'}.get(quality_status['status'], '#95a5a6')

        quality_rect = patches.Rectangle((0.7, 0.85), 0.25, 0.12,
                                       transform=self.ax.transAxes,
                                       facecolor=quality_color, alpha=0.8)
        self.ax.add_patch(quality_rect)

        self.ax.text(0.825, 0.91, f"è´¨é‡: {quality_status['status']}",
                    transform=self.ax.transAxes, fontsize=9,
                    horizontalalignment='center', verticalalignment='center',
                    color='white', fontweight='bold')


class SignalQualityPanel:
    """ä¿¡å·è´¨é‡ç›‘æµ‹é¢æ¿"""

    def __init__(self, fig, ax_position):
        self.fig = fig
        self.ax = fig.add_axes(ax_position)
        self.ax.set_title('ä¿¡å·è´¨é‡ç›‘æµ‹', fontsize=14, fontweight='bold', pad=20)

        # è´¨é‡å†å²
        self.emg_quality_history = deque(maxlen=100)
        self.gsr_quality_history = deque(maxlen=100)

        self._setup_axes()

    def _setup_axes(self):
        """è®¾ç½®åæ ‡è½´"""
        self.ax.set_xlim(0, 100)
        self.ax.set_ylim(0, 1)
        self.ax.set_xlabel('æ—¶é—´ (æ ·æœ¬)', fontsize=10)
        self.ax.set_ylabel('è´¨é‡è¯„åˆ†', fontsize=10)
        self.ax.grid(True, alpha=0.3)

        # æ·»åŠ è´¨é‡ç­‰çº§çº¿
        self.ax.axhline(y=0.7, color='green', linestyle='--', alpha=0.5, label='ä¼˜ç§€')
        self.ax.axhline(y=0.5, color='orange', linestyle='--', alpha=0.5, label='è‰¯å¥½')
        self.ax.axhline(y=0.3, color='red', linestyle='--', alpha=0.5, label='è­¦å‘Š')

    def update(self, emg_quality: SignalQuality, gsr_quality: SignalQuality):
        """æ›´æ–°è´¨é‡ç›‘æµ‹é¢æ¿"""
        # æ·»åŠ åˆ°å†å²è®°å½•
        self.emg_quality_history.append(emg_quality.quality_score)
        self.gsr_quality_history.append(gsr_quality.quality_score)

        # æ¸…é™¤å¹¶é‡ç»˜
        self.ax.clear()
        self._setup_axes()

        if len(self.emg_quality_history) > 1:
            x_data = list(range(len(self.emg_quality_history)))

            # ç»˜åˆ¶è´¨é‡æ›²çº¿
            self.ax.plot(x_data, list(self.emg_quality_history),
                        color='#3498db', linewidth=2, label='EMGè´¨é‡')
            self.ax.plot(x_data, list(self.gsr_quality_history),
                        color='#e74c3c', linewidth=2, label='GSRè´¨é‡')

            # å½“å‰è´¨é‡ç‚¹
            self.ax.scatter(x_data[-1], list(self.emg_quality_history)[-1],
                          color='#3498db', s=100, zorder=5)
            self.ax.scatter(x_data[-1], list(self.gsr_quality_history)[-1],
                          color='#e74c3c', s=100, zorder=5)

        # å›¾ä¾‹
        self.ax.legend(loc='lower right', fontsize=9)

        # è´¨é‡ç»Ÿè®¡ä¿¡æ¯
        if self.emg_quality_history:
            avg_emg = np.mean(list(self.emg_quality_history))
            avg_gsr = np.mean(list(self.gsr_quality_history))

            stats_text = (f"EMG: {avg_emg:.2f}\n"
                         f"GSR: {avg_gsr:.2f}\n"
                         f"SNR: {emg_quality.snr:.1f}dB")

            self.ax.text(0.02, 0.98, stats_text, transform=self.ax.transAxes,
                        fontsize=9, verticalalignment='top',
                        bbox=dict(boxstyle='round,pad=0.5', facecolor='white', alpha=0.9))


class RealtimeEmotionVisualizer:
    """å®æ—¶æƒ…ç»ªå¯è§†åŒ–ä¸»ç³»ç»Ÿ"""

    def __init__(self, config_path: str = 'signal_processing_config.json'):
        # åŠ è½½é…ç½®
        self.config = self._load_config(config_path)

        # åˆå§‹åŒ–ç»„ä»¶
        self.signal_processor = RealTimeSignalProcessor(config_path)
        self.calibration_system = CalibrationSystem(self.config)
        self.emotion_detector = EnsembleDetector(self.config)

        # å¯åŠ¨ä¿¡å·å¤„ç†å™¨
        self.signal_processor.start()

        # åˆ›å»ºå¯è§†åŒ–ç•Œé¢
        self.fig = plt.figure(figsize=(16, 10))
        self.fig.suptitle('EmotionHand å®æ—¶æƒ…ç»ªç›‘æµ‹ç³»ç»Ÿ', fontsize=16, fontweight='bold')

        # é¢æ¿å¸ƒå±€
        self.emotion_panel = EmotionVisualizationPanel(self.fig, [0.05, 0.55, 0.4, 0.35])
        self.quality_panel = SignalQualityPanel(self.fig, [0.05, 0.10, 0.4, 0.35])

        # 3Dæ‰‹åŠ¿å¯è§†åŒ–ï¼ˆä½¿ç”¨ç°æœ‰çš„3Dç³»ç»Ÿï¼‰
        self._setup_3d_visualization()

        # æ€§èƒ½ç›‘æ§
        self.fps_history = deque(maxlen=30)
        self.last_update_time = time.time()

        # æ•°æ®ç”Ÿæˆ
        self.data_generator = self._create_data_generator()

        # è¿è¡ŒçŠ¶æ€
        self.running = False

        logger.info("å®æ—¶æƒ…ç»ªå¯è§†åŒ–ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")

    def _load_config(self, config_path: str) -> Dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            with open(config_path, 'r') as f:
                return json.load(f)
        except Exception as e:
            logger.error(f"é…ç½®åŠ è½½å¤±è´¥: {e}")
            return {}

    def _setup_3d_visualization(self):
        """è®¾ç½®3Dæ‰‹åŠ¿å¯è§†åŒ–"""
        self.ax_3d = self.fig.add_subplot(2, 3, (1, 4), projection='3d')
        self.ax_3d.set_title('3Dæ‰‹åŠ¿å¯è§†åŒ–', fontsize=14, fontweight='bold')

        # æ‰‹åŠ¿å‚æ•°é…ç½®
        self.gesture_params = {
            'Fist': {'fingers': [85, 80, 75, 70], 'intensity': 0.9, 'color': '#8e44ad'},
            'Open': {'fingers': [5, 5, 5, 5], 'intensity': 0.2, 'color': '#95a5a6'},
            'Pinch': {'fingers': [10, 75, 80, 85], 'intensity': 0.7, 'color': '#e67e22'},
            'Point': {'fingers': [10, 10, 10, 80], 'intensity': 0.6, 'color': '#16a085'},
            'Neutral': {'fingers': [20, 20, 20, 20], 'intensity': 0.4, 'color': '#34495e'}
        }

    def _create_data_generator(self):
        """åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆå™¨"""
        class DataGenerator:
            def __init__(self, config):
                self.config = config
                self.time = 0

            def generate_sample(self, emotion_state: str = "Neutral"):
                """ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®æ ·æœ¬"""
                self.time += 0.1

                # åŸºäºæƒ…ç»ªçŠ¶æ€ç”ŸæˆEMGç‰¹å¾
                emotion_emg_params = {
                    'Relaxed': {'rms': 0.15, 'std': 0.08, 'mdf': 80},
                    'Focused': {'rms': 0.45, 'std': 0.25, 'mdf': 120},
                    'Stressed': {'rms': 0.75, 'std': 0.45, 'mdf': 150},
                    'Fatigued': {'rms': 0.25, 'std': 0.15, 'mdf': 60}
                }

                params = emotion_emg_params.get(emotion_state, emotion_emg_params['Neutral'])

                # ç”ŸæˆEMGæ•°æ®
                emg_data = []
                for ch in range(8):
                    base_signal = params['rms'] * np.sin(self.time * (ch + 1) * 0.5)
                    noise = np.random.randn() * params['std']
                    emg_data.append(base_signal + noise)

                # ç”ŸæˆGSRæ•°æ®
                gsr_base = 0.2 if emotion_state == 'Relaxed' else (0.35 if emotion_state in ['Focused', 'Stressed'] else 0.25)
                gsr_data = gsr_base + 0.05 * np.sin(self.time * 0.2) + 0.02 * np.random.randn()

                return emg_data, max(0, gsr_data)

        return DataGenerator(self.config)

    def draw_3d_hand(self, gesture: str, state: str, confidence: float):
        """ç»˜åˆ¶3Dæ‰‹åŠ¿"""
        self.ax_3d.clear()

        # è®¾ç½®3Dè§†å›¾
        self.ax_3d.set_xlim([-1, 1])
        self.ax_3d.set_ylim([-1, 1])
        self.ax_3d.set_zlim([0, 2])
        self.ax_3d.set_xlabel('X', fontsize=10)
        self.ax_3d.set_ylabel('Y', fontsize=10)
        self.ax_3d.set_zlabel('Z', fontsize=10)

        # æ‰‹åŠ¿å‚æ•°
        gesture_config = self.gesture_params.get(gesture, self.gesture_params['Neutral'])
        emotion_config = self.emotion_detector.emotion_config

        # æ‰‹æŒä½ç½®
        palm_vertices = self._generate_palm()

        # æ‰‹æŒ‡
        finger_positions = []
        finger_params = gesture_config['fingers']

        for i, bend_angle in enumerate(finger_params):
            # è®¡ç®—æ‰‹æŒ‡å¼¯æ›²
            base_pos = [0.3 + i * 0.15, 0, 1]
            tip_z = 1.5 - (bend_angle / 90) * 0.5
            finger_positions.append([base_pos[0], base_pos[1], tip_z])

        # é¢œè‰²è®¾ç½®
        emotion_color = emotion_config.get(state, {'color': '#95a5a6'})['color']
        hand_color = gesture_config['color']

        # åŠ¨æ€é€æ˜åº¦
        alpha = 0.3 + 0.7 * confidence

        # ç»˜åˆ¶æ‰‹æŒ
        palm_color = (*self._hex_to_rgb(hand_color), alpha * 0.6)
        for i in range(len(palm_vertices)):
            next_i = (i + 1) % len(palm_vertices)
            xs = [palm_vertices[i][0], palm_vertices[next_i][0]]
            ys = [palm_vertices[i][1], palm_vertices[next_i][1]]
            zs = [palm_vertices[i][2], palm_vertices[next_i][2]]
            self.ax_3d.plot(xs, ys, zs, color=emotion_color, linewidth=3, alpha=alpha)

        # ç»˜åˆ¶æ‰‹æŒ‡
        for i, finger_pos in enumerate(finger_positions):
            # æ‰‹æŒ‡åŸºçº¿
            self.ax_3d.plot([0.3 + i * 0.15, finger_pos[0]],
                          [0, finger_pos[1]],
                          [1, finger_pos[2]],
                          color=emotion_color, linewidth=8 - i, alpha=alpha)

            # æ‰‹æŒ‡å…³èŠ‚
            for j in range(1, 4):
                joint_z = 1 + (finger_pos[2] - 1) * (j / 3)
                self.ax_3d.scatter([0.3 + i * 0.15], [0], [joint_z],
                                 color=emotion_color, s=100, alpha=alpha * 0.8)

        # æ·»åŠ çŠ¶æ€æ ‡ç­¾
        self.ax_3d.text2D(0.05, 0.95, f'çŠ¶æ€: {state}', transform=self.ax_3d.transAxes,
                         fontsize=12, fontweight='bold', color=emotion_color)
        self.ax_3d.text2D(0.05, 0.90, f'æ‰‹åŠ¿: {gesture}', transform=self.ax_3d.transAxes,
                         fontsize=10, color=emotion_color)

    def _generate_palm(self):
        """ç”Ÿæˆæ‰‹æŒé¡¶ç‚¹"""
        size = 0.4
        vertices = [
            [-size, -size, 1],
            [size, -size, 1],
            [size, size, 1],
            [-size, size, 1]
        ]
        return vertices

    def _hex_to_rgb(self, hex_color):
        """åå…­è¿›åˆ¶é¢œè‰²è½¬RGB"""
        hex_color = hex_color.lstrip('#')
        return tuple(int(hex_color[i:i+2], 16) / 255 for i in (0, 2, 4))

    def update_frame(self, frame):
        """æ›´æ–°å¸§æ•°æ®"""
        try:
            # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
            # æ¨¡æ‹Ÿæƒ…ç»ªçŠ¶æ€å˜åŒ–
            emotion_states = ['Relaxed', 'Focused', 'Stressed', 'Fatigued']
            current_emotion = emotion_states[frame % len(emotion_states)]

            emg_data, gsr_data = self.data_generator.generate_sample(current_emotion)

            # æ·»åŠ åˆ°ä¿¡å·å¤„ç†å™¨
            self.signal_processor.add_data(emg_data, gsr_data)

            # å¤„ç†ä¿¡å·
            result = self.signal_processor.process_window()
            if result:
                # æƒ…ç»ªçŠ¶æ€æ£€æµ‹
                prediction = self.emotion_detector.predict_state(
                    result['normalized_features'],
                    result['emg_features'],
                    result['gsr_features']
                )

                # æ›´æ–°å„é¢æ¿
                quality_status = self.signal_processor.get_quality_status()
                self.emotion_panel.update(prediction, quality_status)
                self.quality_panel.update(
                    SignalQuality(**result['quality']['emg']),
                    SignalQuality(**result['quality']['gsr'])
                )

                # æ›´æ–°3Dæ‰‹åŠ¿
                # åŸºäºRMSå€¼é€‰æ‹©æ‰‹åŠ¿
                rms_value = result['normalized_features'].get('rms', 0.5)
                if rms_value > 0.6:
                    gesture = 'Fist'
                elif rms_value > 0.3:
                    gesture = 'Pinch'
                else:
                    gesture = 'Open'

                self.draw_3d_hand(gesture, prediction.state.value, prediction.confidence)

            # æ€§èƒ½ç›‘æ§
            current_time = time.time()
            frame_time = current_time - self.last_update_time
            self.fps_history.append(1.0 / frame_time if frame_time > 0 else 0)
            self.last_update_time = current_time

            # æ˜¾ç¤ºFPS
            if len(self.fps_history) > 0:
                avg_fps = np.mean(list(self.fps_history))
                self.fig.suptitle(f'EmotionHand å®æ—¶æƒ…ç»ªç›‘æµ‹ç³»ç»Ÿ - FPS: {avg_fps:.1f}',
                                fontsize=16, fontweight='bold')

        except Exception as e:
            logger.error(f"å¸§æ›´æ–°å¤±è´¥: {e}")

    def start_visualization(self):
        """å¯åŠ¨å¯è§†åŒ–"""
        self.running = True
        self.animation = FuncAnimation(
            self.fig, self.update_frame,
            interval=int(1000 / self.config['realtime']['target_fps']),
            blit=False
        )
        plt.show()

    def stop_visualization(self):
        """åœæ­¢å¯è§†åŒ–"""
        self.running = False
        if hasattr(self, 'animation'):
            self.animation.event_source.stop()

    def show_performance_stats(self):
        """æ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡"""
        stats = self.signal_processor.get_performance_stats()
        print(f"\nğŸš€ æ€§èƒ½ç»Ÿè®¡:")
        print(f"  å¹³å‡å¤„ç†æ—¶é—´: {stats['avg_time']*1000:.1f}ms")
        print(f"  æœ€å¤§å¤„ç†æ—¶é—´: {stats['max_time']*1000:.1f}ms")
        print(f"  å¤„ç†FPS: {stats['fps']:.1f}")
        print(f"  å»¶è¿Ÿ: {stats.get('latency_ms', stats['avg_time']*1000):.1f}ms")


def main():
    """ä¸»å‡½æ•°"""
    logging.basicConfig(level=logging.INFO)

    print("ğŸ­ EmotionHand å®æ—¶æƒ…ç»ªå¯è§†åŒ–ç³»ç»Ÿ")
    print("=" * 50)

    try:
        # åˆ›å»ºå¯è§†åŒ–ç³»ç»Ÿ
        visualizer = RealtimeEmotionVisualizer()

        print("âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        print("ğŸ“Š æ­£åœ¨å¯åŠ¨å®æ—¶ç›‘æµ‹...")
        print("ğŸ’¡ æç¤º: å…³é—­çª—å£ä»¥é€€å‡ºç³»ç»Ÿ")

        # æ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡
        visualizer.show_performance_stats()

        # å¯åŠ¨å¯è§†åŒ–
        visualizer.start_visualization()

    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ ç³»ç»Ÿé”™è¯¯: {e}")
        logger.exception("ç³»ç»Ÿè¿è¡Œå¼‚å¸¸")
    finally:
        # æ¸…ç†èµ„æº
        if 'visualizer' in locals():
            visualizer.stop_visualization()
            visualizer.signal_processor.stop()
        print("ğŸ”š ç³»ç»Ÿå·²å…³é—­")


if __name__ == "__main__":
    main()