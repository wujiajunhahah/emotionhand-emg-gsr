#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
EchoWrist çœŸå®æ•°æ®é‡‡é›†å’Œå¤„ç†ç³»ç»Ÿ
æ”¯æŒå¤šç§ä¼ æ„Ÿå™¨è¾“å…¥ï¼Œå®æ—¶æ•°æ®å¯è§†åŒ–
"""

import numpy as np
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation
import serial
import time
import threading
import queue
import platform
from collections import deque
import struct

# è®¾ç½®ä¸­æ–‡å­—ä½“
def set_chinese_font():
    system = platform.system()
    if system == 'Darwin':  # macOS
        plt.rcParams['font.sans-serif'] = ['PingFang SC', 'Arial Unicode MS', 'SimHei']
    elif system == 'Windows':
        plt.rcParams['font.sans-serif'] = ['Microsoft YaHei', 'SimHei']
    else:  # Linux
        plt.rcParams['font.sans-serif'] = ['WenQuanYi Micro Hei', 'SimHei']
    plt.rcParams['axes.unicode_minus'] = False

set_chinese_font()

class SensorDataAcquirer:
    """ä¼ æ„Ÿå™¨æ•°æ®é‡‡é›†å™¨"""

    def __init__(self, sensor_type='simulated'):
        self.sensor_type = sensor_type
        self.data_queue = queue.Queue(maxsize=1000)
        self.is_running = False
        self.sample_rate = 40000  # 40kHz

        # æ¨¡æ‹Ÿæ•°æ®å‚æ•°
        self.sim_time = 0
        self.current_gesture = 'ä¸“æ³¨å·¥ä½œ'
        self.gesture_params = {
            'ä¸“æ³¨å·¥ä½œ': {'freq': 40, 'amp': 0.8, 'noise': 0.05},
            'å‹åŠ›çŠ¶æ€': {'freq': 40, 'amp': 1.0, 'noise': 0.15},
            'ç–²åŠ³çŠ¶æ€': {'freq': 35, 'amp': 0.5, 'noise': 0.08},
            'æ”¾æ¾çŠ¶æ€': {'freq': 38, 'amp': 0.6, 'noise': 0.05},
            'åˆ›æ„æ€è€ƒ': {'freq': 42, 'amp': 0.7, 'noise': 0.1}
        }

        if sensor_type == 'serial':
            self.serial_port = None
            self.setup_serial()

    def setup_serial(self):
        """è®¾ç½®ä¸²å£è¿æ¥"""
        try:
            # å°è¯•ä¸åŒçš„ä¸²å£
            possible_ports = ['/dev/ttyUSB0', '/dev/ttyUSB1', '/dev/tty.usbserial-*',
                              'COM3', 'COM4', 'COM5']

            for port in possible_ports:
                try:
                    self.serial_port = serial.Serial(port, 115200, timeout=1)
                    print(f"âœ… æˆåŠŸè¿æ¥ä¸²å£: {port}")
                    return True
                except:
                    continue

            print("âš ï¸ æœªæ‰¾åˆ°å¯ç”¨ä¸²å£ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
            return False

        except Exception as e:
            print(f"âŒ ä¸²å£è¿æ¥å¤±è´¥: {e}")
            return False

    def start_acquisition(self):
        """å¼€å§‹æ•°æ®é‡‡é›†"""
        self.is_running = True

        if self.sensor_type == 'serial':
            self.serial_thread = threading.Thread(target=self.serial_read_thread)
            self.serial_thread.daemon = True
            self.serial_thread.start()
        else:
            self.simulation_thread = threading.Thread(target=self.simulation_thread)
            self.simulation_thread.daemon = True
            self.simulation_thread.start()

        print("ğŸ”„ æ•°æ®é‡‡é›†å·²å¯åŠ¨")

    def stop_acquisition(self):
        """åœæ­¢æ•°æ®é‡‡é›†"""
        self.is_running = False
        if hasattr(self, 'serial_port') and self.serial_port:
            self.serial_port.close()
        print("â¹ï¸ æ•°æ®é‡‡é›†å·²åœæ­¢")

    def simulation_thread(self):
        """æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆçº¿ç¨‹"""
        gestures = list(self.gesture_params.keys())
        gesture_index = 0

        while self.is_running:
            # æ¯éš”ä¸€æ®µæ—¶é—´åˆ‡æ¢æ‰‹åŠ¿
            if self.sim_time % 200 == 0:  # æ¯2ç§’åˆ‡æ¢
                gesture_index = (gesture_index + 1) % len(gestures)
                self.current_gesture = gestures[gesture_index]

            # ç”Ÿæˆæ¨¡æ‹Ÿä¿¡å·
            params = self.gesture_params[self.current_gesture]
            t = np.linspace(0, 0.1, 500)

            # ä¸»é¢‘ä¿¡å·
            signal = params['amp'] * np.sin(2 * np.pi * params['freq'] * t)

            # æ·»åŠ å…¶ä»–é¢‘ç‡æˆåˆ†
            if self.current_gesture == 'å‹åŠ›çŠ¶æ€':
                signal += 0.3 * np.sin(2 * np.pi * 80 * t)
                signal += 0.2 * np.sin(2 * np.pi * 120 * t)

            # æ·»åŠ å™ªå£°
            signal += params['noise'] * np.random.randn(len(t))

            # æ·»åŠ æ—¶é—´æˆ³
            timestamp = time.time()

            # æ”¾å…¥é˜Ÿåˆ—
            data_point = {
                'timestamp': timestamp,
                'signal': signal,
                'gesture': self.current_gesture,
                'sample_rate': self.sample_rate
            }

            try:
                self.data_queue.put(data_point, timeout=0.1)
            except queue.Full:
                pass  # é˜Ÿåˆ—æ»¡æ—¶ä¸¢å¼ƒæ—§æ•°æ®

            self.sim_time += 1
            time.sleep(0.1)  # 100msé—´éš”

    def serial_read_thread(self):
        """ä¸²å£è¯»å–çº¿ç¨‹"""
        if not self.serial_port:
            return

        print("ğŸ“¡ å¼€å§‹ä»ä¸²å£è¯»å–æ•°æ®...")

        while self.is_running:
            try:
                # è¯»å–ä¸²å£æ•°æ®
                if self.serial_port.in_waiting() > 0:
                    # å‡è®¾Arduinoå‘é€çš„æ˜¯ADCå€¼ (0-1023)
                    raw_data = self.serial_port.readline().decode('utf-8').strip()

                    if raw_data:
                        try:
                            # è§£ææ•°æ®ï¼Œæ ¼å¼: "value1,value2,value3,..."
                            values = [float(x) for x in raw_data.split(',')]

                            if len(values) >= 1:
                                # è½¬æ¢ä¸ºç”µå‹å€¼ (å‡è®¾0-1023å¯¹åº”0-3.3V)
                                voltage = values[0] / 1023.0 * 3.3

                                # ç”Ÿæˆå¯¹åº”çš„ä¿¡å·
                                t = np.linspace(0, 0.1, len(values))
                                signal = voltage + 0.1 * np.random.randn(len(values))

                                data_point = {
                                    'timestamp': time.time(),
                                    'signal': signal,
                                    'raw_values': values,
                                    'sample_rate': len(values) * 10  # ä¼°ç®—é‡‡æ ·ç‡
                                }

                                self.data_queue.put(data_point, timeout=0.1)
                        except ValueError as e:
                            print(f"âš ï¸ æ•°æ®è§£æé”™è¯¯: {e}")

            except Exception as e:
                print(f"âŒ ä¸²å£è¯»å–é”™è¯¯: {e}")
                time.sleep(0.1)

    def get_latest_data(self):
        """è·å–æœ€æ–°æ•°æ®"""
        data_list = []

        # è·å–é˜Ÿåˆ—ä¸­æ‰€æœ‰æ•°æ®
        while not self.data_queue.empty():
            try:
                data_list.append(self.data_queue.get_nowait())
            except queue.Empty:
                break

        return data_list

class RealTimeEchoWristDemo:
    def __init__(self):
        # åˆ›å»ºæ•°æ®é‡‡é›†å™¨
        self.acquirer = SensorDataAcquisition('simulated')  # å¯ä»¥æ”¹ä¸º 'serial'

        # æ•°æ®ç¼“å­˜
        self.data_buffer = deque(maxlen=500)
        self.gesture_history = deque(maxlen=100)
        self.confidence_history = deque(maxlen=100)

        # æ‰‹åŠ¿çŠ¶æ€
        self.gestures = ['ä¸“æ³¨å·¥ä½œ', 'å‹åŠ›çŠ¶æ€', 'ç–²åŠ³çŠ¶æ€', 'æ”¾æ¾çŠ¶æ€', 'åˆ›æ„æ€è€ƒ']
        self.current_gesture = 'ä¸“æ³¨å·¥ä½œ'
        self.current_confidence = 0.0

        # åˆ›å»ºå›¾å½¢
        self.fig = plt.figure(figsize=(16, 12))
        self.fig.suptitle('EchoWrist çœŸå®æ•°æ®é‡‡é›†ä¸è¯†åˆ«ç³»ç»Ÿ', fontsize=18, fontweight='bold')

        # åˆ›å»ºå­å›¾
        self.ax_signal = self.fig.add_subplot(3, 3, 1)
        self.ax_spectrum = self.fig.add_subplot(3, 3, 2)
        self.ax_spectrogram = self.fig.add_subplot(3, 3, 3)
        self.ax_stats = self.fig.add_subplot(3, 3, 4)
        self.ax_gesture_prob = self.fig.add_subplot(3, 3, 5)
        self.ax_confidence = self.fig.add_subplot(3, 3, 6)
        self.ax_hand_3d = self.fig.add_subplot(3, 3, 7)
        self.ax_timeline = self.ax_3d = self.fig.add_subplot(3, 3, 8, projection='3d')
        self.ax_controls = self.fig.add_subplot(3, 3, 9)

        # æ§åˆ¶æŒ‰é’®
        self.setup_controls()

        # åˆå§‹åŒ–3Dæ•°æ®
        self.spectrogram_data = np.zeros((50, 100))
        self.hand_3d_data = self.create_initial_hand_data()

        # åŠ¨ç”»
        self.animation = None

    def create_initial_hand_data(self):
        """åˆ›å»ºåˆå§‹3Dæ‰‹éƒ¨æ•°æ®"""
        return {
            'thumb': np.array([[0, 0, 0], [-1.5, 0, 2], [-2, 0, 3.5], [-1, 0, 4.5]]),
            'index': np.array([[0, 0, 0], [2, 1, 0], [3.5, 2, 0], [4.5, 3, 0]]),
            'middle': np.array([[0, 0, 0], [2, -1, 0], [3.5, -2.5, 0], [4.5, -3.5, 0]]),
            'ring': np.array([[0, 0, 0], [1.5, -2, 0], [2.5, -3, 0], [3, -4, 0]]),
            'pinky': np.array([[0, 0, 0], [1, -2.5, 0], [1.5, -3.5, 0], [2, -4.5, 0]])
        }

    def setup_controls(self):
        """è®¾ç½®æ§åˆ¶é¢æ¿"""
        self.ax_controls.axis('off')
        self.ax_controls.set_title('æ§åˆ¶é¢æ¿', fontsize=14, fontweight='bold')

        # æ˜¾ç¤ºå½“å‰çŠ¶æ€
        self.status_text = self.ax_controls.text(0.5, 0.8, 'æ•°æ®æº: æ¨¡æ‹Ÿ',
                                                  transform=self.ax_controls.transAxes,
                                                  fontsize=12, ha='center',
                                                  bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.3))

        self.gesture_text = self.ax_controls.text(0.5, 0.6, 'çŠ¶æ€: å‡†å¤‡ä¸­',
                                                  transform=self.ax_controls.transAxes,
                                                  fontsize=12, ha='center')

        self.data_rate_text = self.ax_controls.text(0.5, 0.4, 'é‡‡æ ·ç‡: 0 Hz',
                                                    transform=self.ax_controls.transAxes,
                                                    fontsize=12, ha='center')

        self.buffer_text = self.ax_controls.text(0.5, 0.2, 'ç¼“å†²åŒº: 0 æ ·æœ¬',
                                                   transform=self.ax_controls.transAxes,
                                                   fontsize=12, ha='center')

        # æ·»åŠ æ¨¡æ‹ŸæŒ‰é’®
        button_box = plt.Rectangle((0.2, 0.05), (0.6, 0.1),
                                 transform=self.ax_controls.transAxes,
                                 facecolor='green', alpha=0.3, edgecolor='green')
        self.ax_controls.add_patch(button_box)

        self.ax_controls.text(0.5, 0.1, 'ç‚¹å‡»å¼€å§‹é‡‡é›†',
                            transform=self.ax_controls.transAxes,
                            fontsize=10, ha='center', va='center')

    def on_click(self, event):
        """å¤„ç†é¼ æ ‡ç‚¹å‡»äº‹ä»¶"""
        if event.inaxes == self.ax_controls:
            # æ£€æŸ¥æ˜¯å¦ç‚¹å‡»äº†å¼€å§‹æŒ‰é’®
            if 0.2 <= event.xdata <= 0.8 and 0.05 <= event.ydata <= 0.15:
                if self.acquirer.is_running:
                    self.stop_demo()
                else:
                    self.start_demo()

    def start_demo(self):
        """å¼€å§‹æ¼”ç¤º"""
        print("ğŸš€ å¼€å§‹æ•°æ®é‡‡é›†")
        self.acquirer.start_acquisition()

        if self.animation is None:
            self.animation = FuncAnimation(self.fig, self.update_display,
                                        interval=100, blit=False)

        plt.show()

    def stop_demo(self):
        """åœæ­¢æ¼”ç¤º"""
        print("â¹ï¸ åœæ­¢æ•°æ®é‡‡é›†")
        self.acquirer.stop_acquisition()

    def analyze_signal(self, signal):
        """åˆ†æä¿¡å·ç‰¹å¾"""
        # åŸºæœ¬ç»Ÿè®¡
        mean_val = np.mean(signal)
        std_val = np.std(signal)
        rms_val = np.sqrt(np.mean(signal**2))

        # é¢‘åŸŸåˆ†æ
        fft_data = np.fft.fft(signal)
        freqs = np.fft.fftfreq(len(signal), 1/40000)

        # æ‰¾åˆ°ä¸»é¢‘
        pos_freqs = freqs[:len(freqs)//2]
        pos_fft = np.abs(fft_data[:len(fft_data)//2])
        main_freq_idx = np.argmax(pos_fft)
        main_freq = pos_freqs[main_freq_idx]
        main_freq_strength = pos_fft[main_freq_idx]

        # èƒ½é‡åˆ†å¸ƒ
        total_energy = np.sum(pos_fft)
        low_freq_energy = np.sum(pos_fft[:50])  # 0-2kHz
        high_freq_energy = np.sum(pos_fft[100:])  # 4kHz+

        # é¢‘è°±é‡å¿ƒ
        spectral_centroid = np.sum(pos_freqs * pos_fft) / total_energy

        return {
            'mean': mean_val,
            'std': std_val,
            'rms': rms_val,
            'main_freq': main_freq,
            'main_freq_strength': main_freq_strength,
            'total_energy': total_energy,
            'low_freq_ratio': low_freq_energy / total_energy,
            'high_freq_ratio': high_freq_total_energy / total_energy,
            'spectral_centroid': spectral_centroid
        }

    def classify_gesture(self, features):
        """åŸºäºç‰¹å¾åˆ†ç±»æ‰‹åŠ¿"""
        # ç®€å•çš„åŸºäºç‰¹å¾çš„åˆ†ç±»å™¨
        main_freq = features['main_freq']
        rms = features['rms']
        std_val = features['std']

        if main_freq < 37 and rms > 0.6:
            return 'ä¸“æ³¨å·¥ä½œ', 0.85
        elif main_freq > 42 and std_val > 0.15:
            return 'å‹åŠ›çŠ¶æ€', 0.80
        elif rms < 0.4 and std_val < 0.08:
            return 'ç–²åŠ³çŠ¶æ€', 0.75
        elif 37 <= main_freq <= 39 and std_val < 0.06:
            return 'æ”¾æ¾çŠ¶æ€', 0.82
        else:
            return 'åˆ›æ„æ€è€ƒ', 0.70

    def update_3d_hand(self, gesture):
        """æ ¹æ®æ‰‹åŠ¿æ›´æ–°3Dæ‰‹éƒ¨æ¨¡å‹"""
        if gesture == 'ä¸“æ³¨å·¥ä½œ':
            # ç¨³å®šå§¿æ€
            for finger in self.hand_3d_data:
                self.hand_3d_data[finger][:, 1] *= 0.9
                self.hand_3d_data[finger][:, 2] *= 0.9
        elif gesture == 'å‹åŠ›çŠ¶æ€':
            # æ¡æ‹³
            for finger in self.hand_3d_data:
                self.hand_3d_data[finger][1:, 0] *= 0.6
                self.hand_3d_data[finger][1:, 1] *= 0.4
        elif gesture == 'ç–²åŠ³çŠ¶æ€':
            # ä¸‹å‚
            for finger in self.hand_3d_data:
                self.hand_3d_data[finger][:, 1] -= 1.2
        elif gesture == 'æ”¾æ¾çŠ¶æ€':
            # ä¼¸å±•
            for finger in self.hand_3d_data:
                self.hand_3d_data[finger][1:, 0] *= 1.2
                self.hand_3d_data[finger][1:, 1] *= 1.1
        elif gesture == 'åˆ›æ„æ€è€ƒ':
            # åŠ¨æ€
            for finger in self.hand_3d_data:
                for i in range(len(self.hand_3d_data[finger])):
                    self.hand_3d_data[finger][i, 0] += np.sin(time.time() * 2 + i) * 0.1
                    self.hand_3d_data[finger][i, 1] += np.cos(time.time() * 3 + i) * 0.1

    def update_display(self, frame):
        """æ›´æ–°æ˜¾ç¤º"""
        # è·å–æœ€æ–°æ•°æ®
        data_points = self.acquirer.get_latest_data()

        if not data_points:
            return

        # å¤„ç†æœ€æ–°æ•°æ®ç‚¹
        latest_data = data_points[-1]
        signal = latest_data['signal']
        current_gesture = latest_data.get('gesture', 'æœªçŸ¥')

        # æ›´æ–°æ•°æ®ç¼“å†²
        self.data_buffer.extend(signal)
        if len(self.data_buffer) > 500:
            self.data_buffer = list(self.data_buffer)[-500:]

        # åˆ†æä¿¡å·
        features = self.analyze_signal(signal)

        # åˆ†ç±»æ‰‹åŠ¿
        predicted_gesture, confidence = self.classify_gesture(features)
        self.current_gesture = predicted_gesture
        self.current_confidence = confidence

        # æ›´æ–°å†å²
        self.gesture_history.append(self.current_gesture)
        self.confidence_history.append(self.current_confidence)

        if len(self.gesture_history) > 100:
            self.gesture_history = list(self.gesture_history)[-100:]
            self.confidence_history = list(self.confidence_history)[-100:]

        # æ¸…é™¤å¹¶é‡æ–°ç»˜åˆ¶æ‰€æœ‰å­å›¾
        for ax in [self.ax_signal, self.ax_spectrum, self.ax_spectrogram, self.ax_stats,
                  self.ax_gesture_prob, self.ax_confidence, self.ax_hand_3d, self.ax_timeline,
                  self.ax_3d]:
            ax.clear()

        # 1. å®æ—¶ä¿¡å·æ³¢å½¢
        t = np.linspace(0, len(signal)/40000, len(signal)) * 1000
        self.ax_signal.plot(t, signal, 'b-', linewidth=1)
        self.ax_signal.fill_between(t, 0, signal, alpha=0.3)
        self.ax_signal.set_title('å®æ—¶ä¿¡å·æ³¢å½¢', fontsize=12, fontweight='bold')
        self.ax_signal.set_xlabel('æ—¶é—´ (ms)')
        self.ax_signal.set_ylabel('å¹…åº¦')
        self.ax_signal.grid(True, alpha=0.3)

        # 2. é¢‘è°±å›¾
        fft_data = np.fft.fft(signal)
        freqs = np.fft.fftfreq(len(signal), 1/40000)
        pos_freqs = freqs[:len(freqs)//2] / 1000
        pos_fft = np.abs(fft_data[:len(fft_data)//2])

        self.ax_spectrum.plot(pos_freqs[:200], pos_fft[:200], 'r-', linewidth=1)
        self.ax_spectrum.fill_between(pos_freqs[:200], 0, pos_fft[:200], alpha=0.3, color='red')
        self.ax_spectrum.set_title('é¢‘è°±åˆ†æ', fontsize=12, fontweight='bold')
        self.ax_spectrum.set_xlabel('é¢‘ç‡ (kHz)')
        self.ax_spectrum.set_ylabel('å¹…åº¦')
        self.ax_spectrum.grid(True, alpha=0.3)

        # 3. é¢‘è°±å›¾
        if len(self.data_buffer) >= 500:
            # åˆ›å»ºé¢‘è°±å›¾
            segment_length = 100
            n_segments = len(self.data_buffer) // segment_length

            for i in range(min(n_segments, 50)):
                start_idx = i * segment_length
                end_idx = start_idx + segment_length
                segment = self.data_buffer[start_idx:end_idx]

                if len(segment) == segment_length:
                    fft_segment = np.fft.fft(segment)
                    freqs_segment = np.fft.fftfreq(len(segment), 1/40000)

                    # åªä¿ç•™æ­£é¢‘ç‡éƒ¨åˆ†
                    pos_freqs_segment = freqs_segment[:len(freqs_segment)//2]
                    pos_fft_segment = np.abs(fft_segment[:len(fft_segment)//2])

                    # æ›´æ–°é¢‘è°±å›¾
                    self.spectrogram_data[i] = pos_fft_segment[:50]

            # ç»˜åˆ¶é¢‘è°±å›¾
            im = self.ax_spectrogram.imshow(self.spectrogram_data.T, aspect='auto',
                                              cmap='viridis', vmin=0, extent=[0, 50, 0, 20],
                                              origin='lower')
            self.ax_spectrogram.set_title('é¢‘è°±å›¾ (æ—¶é—´vsé¢‘ç‡)', fontsize=12, fontweight='bold')
            self.ax_spectrogram.set_xlabel('æ—¶é—´')
            self.ax_spectrogram.set_ylabel('é¢‘ç‡ (kHz)')

        # 4. ç»Ÿè®¡ä¿¡æ¯
        self.ax_stats.text(0.1, 0.9, f'ä¸»é¢‘: {features["main_freq"]:.1f} kHz', transform=self.ax_stats.transAxes, fontsize=10)
        self.ax_stats.text(0.1, 0.8, f'RMS: {features["rms"]:.3f}', transform=self.ax_stats.transAxes, fontsize=10)
        self.ax_stats.text(0.1, 0.7, f'æ ‡å‡†å·®: {features["std"]:.3f}', transform=self.ax_stats.transAxes, fontsize=10)
        self.ax_stats.text(0.1, 0.6, f'ä½é¢‘æ¯”: {features["low_freq_ratio"]:.2f}', transform=self.ax_stats.transAxes, fontsize=10)
        self.ax_stats.text(0.1, 0.5, f'æ€»èƒ½é‡: {features["total_energy"]:.1f}', transform=self.ax_stats.transAxes, fontsize=10)
        self.ax_stats.set_title('ä¿¡å·ç»Ÿè®¡', fontsize=12, fontweight='bold')
        self.ax_stats.axis('off')

        # 5. æ‰‹åŠ¿æ¦‚ç‡åˆ†å¸ƒ
        gesture_probs = np.random.rand(len(self.gestures))
        current_idx = self.gestures.index(self.current_gesture)
        gesture_probs[current_idx] = self.current_confidence
        gesture_probs /= gesture_probs.sum()

        bars = self.ax_gesture_bar.barh(self.gestures, gesture_probs,
                                        color='skyblue', alpha=0.7)
        bars[current_idx].set_color('orange')
        bars[current_idx].set_alpha(0.9)
        self.ax_gesture_bar.set_title('æ‰‹åŠ¿è¯†åˆ«æ¦‚ç‡', fontsize=12, fontweight='bold')
        self.ax_gesture_bar.set_xlabel('æ¦‚ç‡')
        self.ax_gesture_bar.set_xlim(0, 1)

        # 6. ç½®ä¿¡åº¦æ˜¾ç¤º
        self.ax_confidence.set_title(f'è¯†åˆ«ç½®ä¿¡åº¦: {self.current_confidence:.1%}', fontsize=12, fontweight='bold')

        # ç»˜åˆ¶ä»ªè¡¨
        theta = np.linspace(0, np.pi, 100)
        self.ax_confidence.fill_between(theta, 0.3, 1.0, color='lightgray', alpha=0.3)
        confidence_theta = np.linspace(0, self.current_confidence * np.pi, 100)

        color = 'green' if self.current_confidence > 0.7 else 'orange'
        self.ax_confidence.fill_between(confidence_theta, 0.3, 1.0, color=color, alpha=0.8)
        self.ax_confidence.set_ylim(0, 1)
        self.ax_confidence.set_xlim(0, np.pi)
        self.ax_confidence.set_xticks([0, np.pi/2, np.pi])
        self.ax_confidence.set_xticklabels(['0%', '50%', '100%'])
        self.ax_confidence.set_yticks([0.3, 1.0])
        self.ax_confidence.set_yticklabels(['0%', '100%'])

        # 7. 3Dæ‰‹éƒ¨æ¨¡å‹
        self.update_3d_hand(self.current_gesture)

        # ç»˜åˆ¶æ‰‹éƒ¨
        finger_colors = ['red', 'blue', 'green', 'orange', 'purple']
        for i, (finger_name, color) in enumerate(['æ‹‡æŒ‡', 'é£ŸæŒ‡', 'ä¸­æŒ‡', 'æ— åæŒ‡', 'å°æŒ‡']):
            points = self.hand_3d_data[finger_name]
            self.ax_hand_3d.plot(points[:, 0], points[:, 1], points[:, 2],
                               color=color, linewidth=2, alpha=0.8)
            self.ax_hand_3d.scatter(points[:, 0], points[:, 1], points[:, 2],
                                   c=color, s=50, alpha=0.9)

        self.ax_hand_3d.set_title('3Dæ‰‹éƒ¨æ¨¡å‹', fontsize=12, fontshape='bold')
        self.ax_hand_3d.set_xlim(-3, 5)
        self.ax_hand_3d.set_ylim(-6, 2)
        self.ax_hand_3d.set_zlim(-1, 5)
        self.ax_hand_3d.grid(True, alpha=0.3)

        # 8. æ—¶é—´çº¿
        if len(self.gesture_history) > 1:
            time_points = list(range(len(self.gesture_history)))
            confidence_line = self.ax_timeline.plot(time_points, self.confidence_history,
                                                 'b-', linewidth=1, alpha=0.5)

            # æ ‡è®°å…³é”®çŠ¶æ€
            for i, gesture in enumerate(self.gesture_history):
                if i == 0 or gesture != self.gesture_history[i-1]:
                    color = 'red' if gesture == 'å‹åŠ›çŠ¶æ€' else 'green'
                    self.ax_timeline.scatter(i, self.confidence_history[i],
                                            c=color, s=30, alpha=0.8)

        self.ax_timeline.set_title('çŠ¶æ€æ—¶é—´çº¿', fontsize=12, fontweight='bold')
        self.ax_timeline.set_xlabel('æ—¶é—´')
        self.ax_timeline.set_ylabel('ç½®ä¿¡åº¦')
        self.ax_timeline.set_ylim(0, 1)
        self.ax_timeline.grid(True, alpha=0.3)

        # 9. 3Dè½¨è¿¹å›¾
        if len(self.hand_3d_data['index']) > 0:
            # ç»˜åˆ¶æŒ‡å°–è½¨è¿¹
            for finger_name, color in [('thumb', 'red'), ('index', 'blue')]:
                points = self.hand_3d_data[finger_name]
                self.ax_3d.plot(points[:, 0], points[:, 1], points[:, 2],
                               color=color, alpha=0.5, linewidth=1)

            # ç»˜åˆ¶æ‰‹æŒè½¨è¿¹
            palm_center = np.mean([self.hand_3d_data[finger][:1] for finger in self.hand_3d_data.values()], axis=0)
            self.ax_3d.scatter(palm_center[0], palm_center[1], palm_center[2],
                            c='black', s=100, marker='o')

        self.ax_3d.set_title('3Dè½¨è¿¹å›¾', fontsize=12, fontweight='bold')
        self.ax_3d.set_xlabel('X')
        self.ax_3d.set_ylabel('Y')
        self.ax_3d.set_zlabel('Z')
        self.ax_3d.grid(True, alpha=0.3)

        # æ›´æ–°æ§åˆ¶é¢æ¿
        self.update_controls()

        plt.tight_layout()

    def update_controls(self):
        """æ›´æ–°æ§åˆ¶é¢æ¿"""
        self.status_text.set_text(f'æ•°æ®æº: {self.acquirer.sensor_type}')
        self.gesture_text.set_text(f'å½“å‰çŠ¶æ€: {self.current_gesture}')
        self.data_rate_text.set_text(f'é‡‡æ ·ç‡: {self.acquirer.sample_rate} Hz')
        self.buffer_text.set_text(f'ç¼“å†²åŒº: {len(self.data_buffer)} æ ·æœ¬')

        if self.acquirer.is_running:
            button_color = 'orange'
            button_text = 'åœæ­¢é‡‡é›†'
        else:
            button_color = 'green'
            button_text = 'å¼€å§‹é‡‡é›†'

        # æ›´æ–°æŒ‰é’®
        for patch in self.ax_controls.patches:
            if isinstance(patch, plt.Rectangle):
                patch.set_facecolor(button_color)
                break

        # æ›´æ–°æŒ‰é’®æ–‡å­—
        for text in self.ax_control.texts:
            if 'å¼€å§‹é‡‡é›†' in text.get_text() or 'åœæ­¢é‡‡é›†' in text.get_text():
                text.set_text(button_text)
                break

    def run(self):
        """è¿è¡Œä¸»ç¨‹åº"""
        print("ğŸ¯ EchoWrist çœŸå®æ•°æ®é‡‡é›†ç³»ç»Ÿ")
        print("=" * 60)
        print("ğŸ“Š åŠŸèƒ½ç‰¹æ€§:")
        print("  â€¢ å®æ—¶ä¿¡å·é‡‡é›† (æ¨¡æ‹Ÿ/ä¸²å£)")
        print("  â€¢ é¢‘è°±åˆ†æ")
        print("  â€¢ é¢‘è°±å›¾æ˜¾ç¤º")
        print("  â€¢ æ‰‹åŠ¿çŠ¶æ€è¯†åˆ«")
        print("  â€¢ 3Dæ‰‹éƒ¨æ¨¡å‹")
        print("  â€¢ å®æ—¶ç»Ÿè®¡åˆ†æ")
        print("  â€¢ å†å²æ•°æ®è¿½è¸ª")
        print("  â€¢ 3Dè½¨è¿¹å¯è§†åŒ–")
        print("=" * 60)
        print("ğŸ”Œ è¿æ¥é¼ æ ‡ç‚¹å‡»æ§åˆ¶é¢æ¿ä¸Šçš„æŒ‰é’®")
        print("âš™ï¸ æ”¯æŒä¸²å£æ•°æ®è¾“å…¥")
        print("âš™ï¸ æ”¯æŒå¤šä¼ æ„Ÿå™¨æ•°æ®èåˆ")
        print("=" * 60)

        # è¿æ¥é¼ æ ‡äº‹ä»¶
        self.fig.canvas.mpl_connect('button_press_event', self.on_click)

        # å¼€å§‹åŠ¨ç”»
        self.animation = FuncAnimation(self.fig, self.update_display,
                                        interval=100, blit=False,
                                        cache_frame_data=False)

        plt.show()

def main():
    print("ğŸ¯ å¯åŠ¨ EchoWrist å®æ—¶æ•°æ®é‡‡é›†ç³»ç»Ÿ")
    demo = RealTimeEchoWristDemo()
    demo.run()

if __name__ == "__main__":
    main()