#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
EmotionHand æ‰‹éƒ¨æ¨¡å‹å¯è§†åŒ–æ¼”ç¤º
ç”¨å‡æ•°æ®æ¨¡æ‹ŸEMG+GSRä¿¡å·è¯†åˆ«å’ŒUnity 3Då¯è§†åŒ–æ•ˆæœ
"""

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation
from matplotlib.patches import Ellipse, Circle, Rectangle
from matplotlib.collections import PatchCollection
import matplotlib.patches as mpatches
from mpl_toolkits.mplot3d import Axes3D
from mpl_toolkits.mplot3d.art3d import Poly3DCollection
import time
import threading
import queue
from dataclasses import dataclass
from typing import Tuple, List, Dict
import random

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

@dataclass
class EmotionData:
    """æƒ…ç»ªæ•°æ®ç»“æ„"""
    gesture: str
    state: str
    confidence: float
    emg_signal: np.ndarray
    gsr_signal: float
    timestamp: float

class HandModel3D:
    """3Dæ‰‹éƒ¨æ¨¡å‹"""

    def __init__(self):
        # æ‰‹éƒ¨å‡ ä½•å‚æ•° (ç›¸å¯¹å•ä½)
        self.palm_length = 0.85
        self.palm_width = 0.85
        self.finger_lengths = [0.65, 0.75, 0.70, 0.55]  # é£ŸæŒ‡åˆ°å°æŒ‡
        self.thumb_length = 0.55
        self.finger_width = 0.18

        # å…³èŠ‚å‚æ•°
        self.joint_bend_max = [90, 80, 70, 60]  # å„æ‰‹æŒ‡æœ€å¤§å¼¯æ›²è§’åº¦
        self.joint_positions = []
        self.gesture_bends = {
            'Fist': [85, 80, 75, 70],
            'Open': [5, 5, 5, 5],
            'Pinch': [10, 75, 80, 85],
            'Point': [10, 10, 10, 80],
            'Peace': [10, 10, 10, 10],
            'Neutral': [20, 20, 20, 20]
        }

    def get_finger_joints(self, gesture: str, finger_idx: int) -> List[Tuple[float, float, float]]:
        """è®¡ç®—æ‰‹æŒ‡å…³èŠ‚ä½ç½®"""
        bend_angles = self.gesture_bends.get(gesture, [20, 20, 20, 20])
        bend_angle = bend_angles[min(finger_idx, 3)]

        # æ‰‹æŒ‡æ ¹éƒ¨ä½ç½® (åœ¨æ‰‹æŒä¸Š)
        if finger_idx == 0:  # æ‹‡æŒ‡
            base_x, base_y, base_z = -self.palm_width/2, 0, 0
        else:  # å…¶ä»–æ‰‹æŒ‡
            finger_spacing = self.palm_width / 5
            base_x = -self.palm_width/2 + finger_spacing * finger_idx
            base_y, base_z = self.palm_length, 0

        joints = [(base_x, base_y, base_z)]

        # è®¡ç®—å¼¯æ›²åçš„å…³èŠ‚ä½ç½®
        length = self.finger_lengths[min(finger_idx, 3)]
        segments = 3
        segment_length = length / segments

        current_x, current_y, current_z = base_x, base_y, base_z

        for i in range(segments):
            # å¼¯æ›²æ•ˆæœ
            bend_rad = np.radians(bend_angle * (i + 1) / segments)
            current_x += segment_length * np.sin(bend_rad) * 0.3
            current_y += segment_length * np.cos(bend_rad)
            current_z += segment_length * np.sin(bend_rad) * 0.2 * (1 if i % 2 == 0 else -1)
            joints.append((current_x, current_y, current_z))

        return joints

class SignalSimulator:
    """ä¿¡å·æ¨¡æ‹Ÿå™¨"""

    def __init__(self):
        self.sample_rate = 1000
        self.gestures = ['Fist', 'Open', 'Pinch', 'Point', 'Peace', 'Neutral']
        self.states = ['Relaxed', 'Focused', 'Stressed', 'Fatigued']
        self.current_gesture = 'Neutral'
        self.current_state = 'Relaxed'
        self.time = 0

    def generate_emg_signal(self, duration: float, gesture: str) -> np.ndarray:
        """ç”ŸæˆEMGä¿¡å·"""
        n_samples = int(duration * self.sample_rate)
        t = np.linspace(0, duration, n_samples)

        # åŸºç¡€é¢‘ç‡ (è‚Œè‚‰æ´»åŠ¨)
        gesture_frequencies = {
            'Fist': [30, 50, 80, 120, 200],
            'Open': [10, 25, 40, 60, 90],
            'Pinch': [40, 70, 110, 180, 250],
            'Point': [20, 45, 85, 150, 220],
            'Peace': [15, 35, 65, 110, 180],
            'Neutral': [5, 15, 30, 45, 80]
        }

        freqs = gesture_frequencies.get(gesture, [10, 25, 40, 60, 90])
        signal = np.zeros(n_samples)

        # 8é€šé“EMGä¿¡å·
        channels = []
        for ch in range(8):
            channel_signal = 0
            for i, freq in enumerate(freqs):
                amplitude = 0.3 / (i + 1)  # é€’å‡å¹…åº¦
                phase = np.random.random() * 2 * np.pi
                channel_signal += amplitude * np.sin(2 * np.pi * freq * t + phase)

            # æ·»åŠ å™ªå£°
            channel_signal += 0.1 * np.random.randn(n_samples)

            # æ‰‹åŠ¿ç›¸å…³çš„è°ƒåˆ¶
            if gesture != 'Neutral':
                envelope = 0.5 + 0.5 * np.sin(2 * np.pi * 0.5 * t)
                channel_signal *= envelope

            channels.append(channel_signal)

        return np.array(channels).T

    def generate_gsr_signal(self, duration: float, state: str) -> float:
        """ç”ŸæˆGSRä¿¡å·"""
        # çŠ¶æ€ç›¸å…³çš„GSRåŸºçº¿å€¼
        state_values = {
            'Relaxed': 0.1 + 0.05 * np.sin(self.time * 0.1),
            'Focused': 0.2 + 0.08 * np.sin(self.time * 0.15),
            'Stressed': 0.4 + 0.15 * np.sin(self.time * 0.2) + 0.1 * np.random.random(),
            'Fatigued': 0.25 + 0.12 * np.sin(self.time * 0.12)
        }

        return state_values.get(state, 0.15)

    def update(self):
        """æ›´æ–°æ¨¡æ‹Ÿå™¨çŠ¶æ€"""
        self.time += 0.1

        # éšæœºåˆ‡æ¢æ‰‹åŠ¿
        if np.random.random() < 0.05:  # 5%æ¦‚ç‡åˆ‡æ¢æ‰‹åŠ¿
            self.current_gesture = np.random.choice(self.gestures)

        # éšæœºåˆ‡æ¢çŠ¶æ€
        if np.random.random() < 0.03:  # 3%æ¦‚ç‡åˆ‡æ¢çŠ¶æ€
            self.current_state = np.random.choice(self.states)

class EmotionHandVisualizer:
    """EmotionHandå¯è§†åŒ–å™¨"""

    def __init__(self):
        self.hand_model = HandModel3D()
        self.signal_simulator = SignalSimulator()
        self.data_queue = queue.Queue()
        self.current_data = None

        # çŠ¶æ€é¢œè‰²æ˜ å°„
        self.state_colors = {
            'Relaxed': '#3498db',      # è“è‰²
            'Focused': '#2ecc71',      # ç»¿è‰²
            'Stressed': '#e74c3c',     # çº¢è‰²
            'Fatigued': '#f39c12'      # é»„è‰²
        }

        # æ‰‹åŠ¿é¢œè‰²
        self.gesture_colors = {
            'Fist': '#8e44ad',         # ç´«è‰²
            'Open': '#95a5a6',         # ç°è‰²
            'Pinch': '#e67e22',        # æ©™è‰²
            'Point': '#16a085',        # é’è‰²
            'Peace': '#27ae60',        # ç»¿è‰²
            'Neutral': '#34495e'       # æ·±ç°è‰²
        }

    def simulate_real_time_data(self):
        """æ¨¡æ‹Ÿå®æ—¶æ•°æ®æµ"""
        while True:
            # æ›´æ–°æ¨¡æ‹Ÿå™¨
            self.signal_simulator.update()

            # ç”Ÿæˆä¿¡å·æ•°æ®
            emg_signal = self.signal_simulator.generate_emg_signal(
                0.1, self.signal_simulator.current_gesture
            )
            gsr_signal = self.signal_simulator.generate_gsr_signal(
                0.1, self.signal_simulator.current_state
            )

            # åˆ›å»ºæ•°æ®å¯¹è±¡
            data = EmotionData(
                gesture=self.signal_simulator.current_gesture,
                state=self.signal_simulator.current_state,
                confidence=0.6 + 0.3 * np.random.random(),
                emg_signal=emg_signal[-1] if len(emg_signal) > 0 else np.zeros(8),
                gsr_signal=gsr_signal,
                timestamp=time.time()
            )

            # æ”¾å…¥é˜Ÿåˆ—
            if not self.data_queue.full():
                self.data_queue.put(data)

            time.sleep(0.1)  # 100msé—´éš”

    def create_3d_hand_plot(self, fig, position):
        """åˆ›å»º3Dæ‰‹éƒ¨å›¾"""
        ax = fig.add_subplot(2, 3, position, projection='3d')
        ax.set_title('3D Hand Model', fontsize=10, fontweight='bold')

        # è·å–å½“å‰æ•°æ®
        if self.current_data:
            gesture = self.current_data.gesture
            state = self.current_data.state
            confidence = self.current_data.confidence

            # è®¾ç½®é¢œè‰²
            hand_color = self.state_colors.get(state, '#95a5a6')
            alpha = 0.3 + 0.7 * confidence  # é€æ˜åº¦åŸºäºç½®ä¿¡åº¦
        else:
            gesture = 'Neutral'
            state = 'Relaxed'
            hand_color = '#95a5a6'
            alpha = 0.5

        # ç»˜åˆ¶æ‰‹æŒ
        palm_corners = [
            [-self.hand_model.palm_width/2, 0, -self.hand_model.palm_width/2],
            [self.hand_model.palm_width/2, 0, -self.hand_model.palm_width/2],
            [self.hand_model.palm_width/2, 0, self.hand_model.palm_width/2],
            [-self.hand_model.palm_width/2, 0, self.hand_model.palm_width/2]
        ]

        # æ‰‹æŒé¡¶é¢
        palm_top = [[p[0], p[1] + 0.1, p[2]] for p in palm_corners]
        palm_collection = Poly3DCollection([palm_top], alpha=alpha, facecolor=hand_color, edgecolor='black')
        ax.add_collection3d(palm_collection)

        # ç»˜åˆ¶æ‰‹æŒ‡
        for finger_idx in range(5):
            joints = self.hand_model.get_finger_joints(gesture, finger_idx)

            # ç»˜åˆ¶æ‰‹æŒ‡çº¿æ¡
            xs, ys, zs = zip(*joints)
            ax.plot(xs, ys, zs, 'o-', color=hand_color, linewidth=3, markersize=4, alpha=alpha)

        # è®¾ç½®åæ ‡è½´
        ax.set_xlim([-1, 1])
        ax.set_ylim([0, 2])
        ax.set_zlim([-1, 1])
        ax.set_xlabel('X')
        ax.set_ylabel('Y')
        ax.set_zlabel('Z')

        # æ·»åŠ çŠ¶æ€æ–‡æœ¬
        ax.text2D(0.05, 0.95, f'Gesture: {gesture}', transform=ax.transAxes, fontsize=8)
        ax.text2D(0.05, 0.90, f'State: {state}', transform=ax.transAxes, fontsize=8)
        ax.text2D(0.05, 0.85, f'Confidence: {confidence:.2f}' if self.current_data else 'Confidence: 0.00',
                 transform=ax.transAxes, fontsize=8)

        # è®¾ç½®è§†è§’
        ax.view_init(elev=20, azim=45)

    def create_emg_plot(self, fig, position):
        """åˆ›å»ºEMGä¿¡å·å›¾"""
        ax = fig.add_subplot(2, 3, position)
        ax.set_title('EMG Signals (8 Channels)', fontsize=10, fontweight='bold')

        if self.current_data:
            emg_signal = self.current_data.emg_signal

            # ç¡®ä¿emg_signalæ˜¯äºŒç»´æ•°ç»„
            if emg_signal.ndim == 1:
                emg_signal = emg_signal.reshape(1, -1)

            # ç”Ÿæˆå†å²æ•°æ®
            if not hasattr(self, 'emg_history'):
                self.emg_history = []

            self.emg_history.append(emg_signal.copy())
            if len(self.emg_history) > 50:
                self.emg_history.pop(0)

            # ç»˜åˆ¶8é€šé“EMGä¿¡å·
            if len(self.emg_history) > 0:
                # å–æœ€è¿‘çš„æ•°æ®
                recent_data = np.array(self.emg_history[-20:])  # æœ€è¿‘20ä¸ªæ—¶é—´ç‚¹
                time_points = np.arange(recent_data.shape[0]) * 0.1  # 100msé—´éš”

                for i in range(min(8, recent_data.shape[2])):
                    channel_data = recent_data[:, 0, i] if recent_data.shape[1] > 0 else recent_data[:, i]
                    ax.plot(time_points, channel_data + i*0.5,
                           alpha=0.7, linewidth=1.5, label=f'Ch{i+1}' if i < 3 else '')

            ax.set_ylabel('Channel + Offset')
            ax.set_xlabel('Time (s)')
            ax.grid(True, alpha=0.3)
            if len(self.emg_history) > 0 and len(self.emg_history[0]) > 0:
                ax.legend(loc='upper right', fontsize=6)
        else:
            ax.text(0.5, 0.5, 'Waiting for data...', ha='center', va='center', transform=ax.transAxes)

    def create_gsr_plot(self, fig, position):
        """åˆ›å»ºGSRä¿¡å·å›¾"""
        ax = fig.add_subplot(2, 3, position)
        ax.set_title('GSR Signal', fontsize=10, fontweight='bold')

        if self.current_data:
            gsr_value = self.current_data.gsr_signal
            state = self.current_data.state

            # åˆ›å»ºå†å²æ•°æ®æ•°ç»„
            if not hasattr(self, 'gsr_history'):
                self.gsr_history = []

            self.gsr_history.append(gsr_value)
            if len(self.gsr_history) > 100:
                self.gsr_history.pop(0)

            # ç»˜åˆ¶GSRä¿¡å·
            ax.plot(self.gsr_history, color=self.state_colors.get(state, '#95a5a6'), linewidth=2)
            ax.fill_between(range(len(self.gsr_history)), self.gsr_history, alpha=0.3,
                           color=self.state_colors.get(state, '#95a5a6'))

            ax.set_ylabel('GSR Value')
            ax.set_xlabel('Time Steps')
            ax.grid(True, alpha=0.3)

            # æ·»åŠ çŠ¶æ€æ ‡ç­¾
            ax.text(0.02, 0.98, f'State: {state}', transform=ax.transAxes,
                   fontsize=9, va='top',
                   bbox=dict(boxstyle='round', facecolor=self.state_colors.get(state, '#95a5a6'), alpha=0.3))
        else:
            ax.text(0.5, 0.5, 'Waiting for data...', ha='center', va='center', transform=ax.transAxes)

    def create_confidence_plot(self, fig, position):
        """åˆ›å»ºç½®ä¿¡åº¦å›¾"""
        ax = fig.add_subplot(2, 3, position)
        ax.set_title('Prediction Confidence', fontsize=10, fontweight='bold')

        if not hasattr(self, 'confidence_history'):
            self.confidence_history = []

        if self.current_data:
            confidence = self.current_data.confidence
            self.confidence_history.append(confidence)

            if len(self.confidence_history) > 50:
                self.confidence_history.pop(0)

            # ç»˜åˆ¶ç½®ä¿¡åº¦å†å²
            ax.plot(self.confidence_history, 'b-', linewidth=2, label='Confidence')
            ax.axhline(y=0.6, color='r', linestyle='--', alpha=0.7, label='Threshold')

            # ç½®ä¿¡åº¦é¢œè‰²èƒŒæ™¯
            ax.fill_between(range(len(self.confidence_history)), self.confidence_history, 0.6,
                           where=[c >= 0.6 for c in self.confidence_history],
                           alpha=0.3, color='green', label='High Confidence')
            ax.fill_between(range(len(self.confidence_history)), self.confidence_history, 0.6,
                           where=[c < 0.6 for c in self.confidence_history],
                           alpha=0.3, color='red', label='Low Confidence')

            ax.set_ylabel('Confidence')
            ax.set_xlabel('Time Steps')
            ax.set_ylim([0, 1])
            ax.legend(loc='lower right', fontsize=8)
            ax.grid(True, alpha=0.3)
        else:
            ax.text(0.5, 0.5, 'Waiting for data...', ha='center', va='center', transform=ax.transAxes)

    def create_status_panel(self, fig, position):
        """åˆ›å»ºçŠ¶æ€é¢æ¿"""
        ax = fig.add_subplot(2, 3, position)
        ax.set_title('System Status', fontsize=10, fontweight='bold')
        ax.axis('off')

        if self.current_data:
            # çŠ¶æ€ä¿¡æ¯
            info_text = f"""
ğŸ­ EmotionHand Status
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ¤š Gesture: {self.current_data.gesture}
ğŸ˜Œ State: {self.current_data.state}
ğŸ¯ Confidence: {self.current_data.confidence:.2f}
ğŸ“Š EMG Level: {np.mean(np.abs(self.current_data.emg_signal.flatten())):.3f}
ğŸ“ˆ GSR Level: {self.current_data.gsr_signal:.3f}

âš¡ Real-time Performance
â€¢ Latency: ~85ms âœ…
â€¢ Sampling: 1000Hz EMG + 100Hz GSR
â€¢ Update Rate: 10Hz

ğŸ¨ Visualization Effects
â€¢ Color: {self.current_data.state}
â€¢ Particles: {"Active" if self.current_data.confidence > 0.6 else "Inactive"}
â€¢ Hand Model: {self.current_data.gesture}
            """

            ax.text(0.1, 0.9, info_text, transform=ax.transAxes, fontsize=8,
                   verticalalignment='top', fontfamily='monospace',
                   bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))
        else:
            ax.text(0.5, 0.5, 'ğŸ”„ Initializing...\nWaiting for sensor data',
                   ha='center', va='center', transform=ax.transAxes, fontsize=12)

    def create_feature_plot(self, fig, position):
        """åˆ›å»ºç‰¹å¾åˆ†æå›¾"""
        ax = fig.add_subplot(2, 3, position)
        ax.set_title('Feature Analysis', fontsize=10, fontweight='bold')

        if self.current_data:
            emg_signal = self.current_data.emg_signal
            # ç¡®ä¿emg_signalæ˜¯ä¸€ç»´æ•°ç»„
            if emg_signal.ndim > 1:
                emg_signal = emg_signal.flatten()

            # æ¨¡æ‹Ÿç‰¹å¾æ•°æ®
            features = [
                np.mean(np.abs(emg_signal)),                    # RMS
                np.std(emg_signal),                             # STD
                np.sum(np.diff(np.sign(emg_signal)) != 0),      # ZC
                np.sum(np.abs(np.diff(emg_signal))),            # WL
                self.current_data.gsr_signal,                    # GSR Mean
                0.1 + 0.05 * np.random.random()                 # GSR STD
            ]

            feature_names = ['RMS', 'STD', 'ZC', 'WL', 'GSR-Mean', 'GSR-STD']
            colors = ['#3498db', '#2ecc71', '#e74c3c', '#f39c12', '#9b59b6', '#1abc9c']

            bars = ax.bar(feature_names, features, color=colors, alpha=0.7)
            ax.set_ylabel('Feature Value')
            ax.tick_params(axis='x', rotation=45)
            ax.grid(True, alpha=0.3)

            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for bar, value in zip(bars, features):
                height = bar.get_height()
                ax.text(bar.get_x() + bar.get_width()/2., height,
                       f'{value:.2f}', ha='center', va='bottom', fontsize=8)
        else:
            ax.text(0.5, 0.5, 'Waiting for data...', ha='center', va='center', transform=ax.transAxes)

    def update_plots(self, frame):
        """æ›´æ–°æ‰€æœ‰å›¾è¡¨"""
        # ä»é˜Ÿåˆ—è·å–æœ€æ–°æ•°æ®
        try:
            while not self.data_queue.empty():
                self.current_data = self.data_queue.get_nowait()
        except queue.Empty:
            pass

        # æ¸…é™¤æ‰€æœ‰å­å›¾
        plt.clf()

        # é‡æ–°åˆ›å»ºå›¾è¡¨
        self.create_3d_hand_plot(plt.gcf(), 1)
        self.create_emg_plot(plt.gcf(), 2)
        self.create_gsr_plot(plt.gcf(), 3)
        self.create_confidence_plot(plt.gcf(), 4)
        self.create_feature_plot(plt.gcf(), 5)
        self.create_status_panel(plt.gcf(), 6)

        plt.suptitle('ğŸ­ EmotionHand - Real-time EMG+GSR Visualization Demo',
                    fontsize=14, fontweight='bold')
        plt.tight_layout()

    def run_demo(self):
        """è¿è¡Œæ¼”ç¤º"""
        print("ğŸ­ å¯åŠ¨ EmotionHand å¯è§†åŒ–æ¼”ç¤º...")
        print("ğŸ“Š æ¨¡æ‹Ÿå®æ—¶EMG+GSRæ•°æ®æµ")
        print("ğŸ–ï¸ 3Dæ‰‹éƒ¨æ¨¡å‹å®æ—¶æ¸²æŸ“")
        print("ğŸ“ˆ å¤šç»´åº¦ä¿¡å·åˆ†æ")
        print("âš¡ <100mså»¶è¿Ÿå®æ—¶æ€§èƒ½")
        print("\nâŒ å…³é—­çª—å£åœæ­¢æ¼”ç¤º\n")

        # å¯åŠ¨æ•°æ®æ¨¡æ‹Ÿçº¿ç¨‹
        data_thread = threading.Thread(target=self.simulate_real_time_data, daemon=True)
        data_thread.start()

        # åˆ›å»ºå›¾å½¢
        fig = plt.figure(figsize=(16, 10))
        fig.canvas.manager.set_window_title('EmotionHand - Real-time Visualization Demo')

        # åˆ›å»ºåŠ¨ç”»
        ani = animation.FuncAnimation(fig, self.update_plots, interval=100, blit=False, cache_frame_data=False)

        # æ˜¾ç¤ºå›¾å½¢
        plt.show()

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸ­ EmotionHand æ‰‹éƒ¨æ¨¡å‹å¯è§†åŒ–æ¼”ç¤º")
    print("=" * 60)
    print("ğŸ“‹ æ¼”ç¤ºå†…å®¹:")
    print("  â€¢ 3Dæ‰‹éƒ¨æ¨¡å‹å®æ—¶æ¸²æŸ“")
    print("  â€¢ EMGä¿¡å· (8é€šé“) å®æ—¶æ˜¾ç¤º")
    print("  â€¢ GSRä¿¡å·åŠ¨æ€å˜åŒ–")
    print("  â€¢ æ‰‹åŠ¿è¯†åˆ« (6ç§æ‰‹åŠ¿)")
    print("  â€¢ æƒ…ç»ªçŠ¶æ€è¯†åˆ« (4ç§çŠ¶æ€)")
    print("  â€¢ ç½®ä¿¡åº¦å®æ—¶ç›‘æ§")
    print("  â€¢ ç‰¹å¾åˆ†æå¯è§†åŒ–")
    print("  â€¢ ç³»ç»ŸçŠ¶æ€é¢æ¿")
    print("\nğŸ¨ é¢œè‰²æ˜ å°„:")
    print("  ğŸ”µ Relaxed (æ”¾æ¾)")
    print("  ğŸŸ¢ Focused (ä¸“æ³¨)")
    print("  ğŸ”´ Stressed (å‹åŠ›)")
    print("  ğŸŸ¡ Fatigued (ç–²åŠ³)")
    print("\nğŸ¤š æ‰‹åŠ¿ç±»å‹:")
    print("  â€¢ Fist (æ¡æ‹³)")
    print("  â€¢ Open (å¼ å¼€)")
    print("  â€¢ Pinch (æåˆ)")
    print("  â€¢ Point (æŒ‡ç‚¹)")
    print("  â€¢ Peace (å’Œå¹³)")
    print("  â€¢ Neutral (ä¸­æ€§)")
    print("=" * 60)

    # åˆ›å»ºå¯è§†åŒ–å™¨
    visualizer = EmotionHandVisualizer()

    # è¿è¡Œæ¼”ç¤º
    try:
        visualizer.run_demo()
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ æ¼”ç¤ºå·²åœæ­¢")
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºå‡ºé”™: {e}")

if __name__ == "__main__":
    main()