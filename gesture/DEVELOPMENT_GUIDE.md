# GestureSense äºŒæ¬¡å¼€å‘æŒ‡å—

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®åŸºäº [EchoWrist](https://github.com/xyd22/EchoWrist) å£°çº³æ‰‹åŠ¿è¯†åˆ«ç³»ç»Ÿï¼Œä¸“é—¨é’ˆå¯¹å·¥ä½œçŠ¶æ€æ„ŸçŸ¥åœºæ™¯è¿›è¡ŒäºŒæ¬¡å¼€å‘ã€‚é€šè¿‡æ•´åˆæˆ‘ä»¬çš„æ‰‹åŠ¿è¯†åˆ«æŠ€æœ¯ç ”ç©¶ï¼Œå®ç°éä¾µå…¥å¼çš„å·¥ä½œæ•ˆç‡ç›‘æµ‹ã€‚

## ğŸš€ å¿«é€Ÿå¯åŠ¨

### 1. ç¯å¢ƒé…ç½®

#### æ–¹æ¡ˆA: ä½¿ç”¨Condaç¯å¢ƒ (æ¨è)
```bash
# ä½¿ç”¨é¡¹ç›®æä¾›çš„ç¯å¢ƒæ–‡ä»¶
conda create --name echowrist --file EchoWristEnv.txt
conda activate echowrist
```

#### æ–¹æ¡ˆB: æ‰‹åŠ¨å®‰è£…
```bash
pip install torch torchvision opencv-python matplotlib pandas numpy scipy seaborn scikit-learn
```

### 2. æ•°æ®é‡‡é›†
```bash
cd data_collection
python data_collection.py -cd 6 -c 5fingers -f 2 -r 2 -t 2 -cam 0 --audio True --noserial -p ../datasets -pilot_study
```

### 3. æ•°æ®å¤„ç†
```bash
cd data_preparation
python data_preparation.py -md 500000000 -nd -500000000 -f --path ../datasets/pilot_study
```

### 4. æ¨¡å‹è®­ç»ƒ
```bash
cd dl_model
python train.py -o train_output -f original-ts -p ../datasets/pilot_study
```

## ğŸ”— ç›¸å…³é¡¹ç›®é“¾æ¥

### æ ¸å¿ƒæŠ€æœ¯é¡¹ç›®
- **EchoWrist (ä¸»é¡¹ç›®)**: https://github.com/xyd22/EchoWrist
  - åŸå§‹å£°çº³æ‰‹åŠ¿è¯†åˆ«ç³»ç»Ÿ
  - å®Œæ•´çš„æ•°æ®é‡‡é›†ã€å¤„ç†ã€è®­ç»ƒæµç¨‹

- **Ring-a-Pose (Cornell)**: https://github.com/cornell-lab/ring-a-pose
  - Cornellå¤§å­¦å£°çº³æ‰‹åŠ¿è¯†åˆ«åŸå‹
  - ç†è®ºåŸºç¡€å’ŒæŠ€æœ¯å‚è€ƒ

### ç›¸å…³å¼€æºé¡¹ç›®
- **Solit**: https://github.com/andybarry/Solit
  - å£°çº³æ‰‹åŠ¿è¯†åˆ«çš„æ—©æœŸå®ç°
  - ç¡¬ä»¶è®¾è®¡å’Œä¿¡å·å¤„ç†ç®—æ³•

- **mmWave-Gesture-Recognition**: https://github.com/hughkk/mmWave-Gesture-Recognition
  - æ¯«ç±³æ³¢æ‰‹åŠ¿è¯†åˆ«é¡¹ç›®
  - å¯ä¾›å‚è€ƒçš„ä¿¡å·å¤„ç†æŠ€æœ¯

- **Gesture-Recognition-with-Radar**: https://github.com/mohammadkarimi/Gesture-Recognition-with-Radar
  - é›·è¾¾æ‰‹åŠ¿è¯†åˆ«é¡¹ç›®
  - å¤šç§é›·è¾¾æŠ€æœ¯çš„å®ç°

### å­¦æœ¯èµ„æº
- **Google Scholar - EchoWrist**: https://scholar.google.com/scholar?q=echowrist+gesture+recognition
- **IEEE Xplore - Acoustic Gesture Recognition**: https://ieeexplore.ieee.org/search/searchresult.jsp?newsearch=true&queryText=acoustic%20gesture%20recognition

## ğŸ“ é¡¹ç›®ç»“æ„è¯¦è§£

```
gesture/
â”œâ”€â”€ data_collection/           # æ•°æ®é‡‡é›†æ¨¡å—
â”‚   â”œâ”€â”€ data_collection.py    # ä¸»é‡‡é›†ç¨‹åº
â”‚   â”œâ”€â”€ commands.py           # æ‰‹åŠ¿å‘½ä»¤å®šä¹‰
â”‚   â”œâ”€â”€ speed_study.py        # é€Ÿåº¦ç ”ç©¶å·¥å…·
â”‚   â”œâ”€â”€ audios/               # éŸ³é¢‘å‘½ä»¤æ–‡ä»¶
â”‚   â””â”€â”€ videos/               # ç¤ºèŒƒè§†é¢‘
â”œâ”€â”€ data_preparation/         # æ•°æ®é¢„å¤„ç†æ¨¡å—
â”‚   â”œâ”€â”€ data_preparation.py   # æ•°æ®é¢„å¤„ç†ä¸»ç¨‹åº
â”‚   â”œâ”€â”€ audio_auto_sync.py    # éŸ³è§†é¢‘åŒæ­¥
â”‚   â”œâ”€â”€ echo_profiles.py      # å£°çº³ä¿¡å·å¤„ç†
â”‚   â”œâ”€â”€ visualize.py          # æ•°æ®å¯è§†åŒ–
â”‚   â””â”€â”€ tx_signals/           # å‘å°„ä¿¡å·æ¨¡æ¿
â”œâ”€â”€ dl_model/                 # æ·±åº¦å­¦ä¹ æ¨¡å—
â”‚   â”œâ”€â”€ train.py              # æ¨¡å‹è®­ç»ƒ
â”‚   â”œâ”€â”€ trace_model.py        # å®æ—¶æ¨ç†æ¨¡å‹
â”‚   â”œâ”€â”€ tcp_realtime.py       # TCPå®æ—¶é€šä¿¡
â”‚   â””â”€â”€ libs/                 # æ ¸å¿ƒç®—æ³•åº“
â”œâ”€â”€ my_tools/                 # è¾…åŠ©å·¥å…·
â”‚   â”œâ”€â”€ generate_commands.ipynb  # æ‰‹åŠ¿å‘½ä»¤ç”Ÿæˆ
â”‚   â””â”€â”€ generate_raw.ipynb    # åŸå§‹æ•°æ®ç”Ÿæˆ
â”œâ”€â”€ EchoWristEnv.txt          # Condaç¯å¢ƒé…ç½®
â”œâ”€â”€ rotate_video.py           # è§†é¢‘æ—‹è½¬å·¥å…·
â””â”€â”€ README.md                 # åŸé¡¹ç›®è¯´æ˜
```

## ğŸ”§ ç¡¬ä»¶è¦æ±‚

### ä¼ æ„Ÿå™¨ç¡¬ä»¶
- **è¶…å£°æ³¢ä¼ æ„Ÿå™¨**: 40kHz FMCWä¼ æ„Ÿå™¨
  - æ¨èå‹å·: TR-40-16 (å‘å°„) / RX-40-16 (æ¥æ”¶)
  - è´­ä¹°é“¾æ¥: https://www.mouser.com/ProductDetail/400-TR-40-16

- **å¾®æ§åˆ¶å™¨**:
  - Arduino Nano RP2040: https://www.arduino.cc/en/Guide/NANORP2040Connect
  - ESP32-DevKitC: https://www.espressif.com/en/products/devkits

- **éŸ³é¢‘è®¾å¤‡**:
  - USBå£°å¡: https://www.amazon.com/dp/B07MQ5M4KZ
  - éº¦å…‹é£: https://www.amazon.com/dp/B07K946LWZ

### å¼€å‘ç¡¬ä»¶å»ºè®®
- **å¼€å‘æœº**: é…å¤‡NVIDIA GPU (GTX 1060æˆ–æ›´é«˜)
- **å†…å­˜**: 16GB+ RAM
- **å­˜å‚¨**: 100GB+ å¯ç”¨ç©ºé—´

## ğŸ¯ å·¥ä½œçŠ¶æ€æ„ŸçŸ¥å®šåˆ¶

### 1. æ–°å¢æ‰‹åŠ¿ç±»å‹

åœ¨ `data_collection/commands.py` ä¸­æ·»åŠ å·¥ä½œçŠ¶æ€ç›¸å…³çš„æ‰‹åŠ¿:

```python
WORK_STATE_GESTURES = {
    'focused_work': {
        'name': 'ä¸“æ³¨å·¥ä½œæ‰‹åŠ¿',
        'description': 'ç¨³å®šæ‰‹éƒ¨ï¼Œè½»å¾®æ‰‹æŒ‡æ´»åŠ¨',
        'duration': 3.0,
        'audio_cue': 'focused.wav'
    },
    'stress_state': {
        'name': 'å‹åŠ›çŠ¶æ€æ‰‹åŠ¿',
        'description': 'å¿«é€Ÿå¾®åŠ¨ï¼Œæ¡æ‹³å§¿åŠ¿',
        'duration': 2.5,
        'audio_cue': 'stress.wav'
    },
    'fatigue_state': {
        'name': 'ç–²åŠ³çŠ¶æ€æ‰‹åŠ¿',
        'description': 'æ‰‹éƒ¨ä¸‹å‚ï¼Œç¼“æ…¢è¿åŠ¨',
        'duration': 3.0,
        'audio_cue': 'fatigue.wav'
    },
    'relaxed_state': {
        'name': 'æ”¾æ¾çŠ¶æ€æ‰‹åŠ¿',
        'description': 'æ‰‹éƒ¨å¼ å¼€ï¼Œå¹³æ»‘è¿åŠ¨',
        'duration': 2.5,
        'audio_cue': 'relaxed.wav'
    },
    'creative_thinking': {
        'name': 'åˆ›æ„æ€è€ƒæ‰‹åŠ¿',
        'description': 'å¤šæ ·åŒ–æ‰‹éƒ¨åŠ¨ä½œï¼Œé¢‘ç¹å˜åŒ–',
        'duration': 3.5,
        'audio_cue': 'creative.wav'
    }
}
```

### 2. æ•°æ®é‡‡é›†ç­–ç•¥

é’ˆå¯¹å·¥ä½œçŠ¶æ€æ„ŸçŸ¥çš„æ•°æ®é‡‡é›†å»ºè®®:

```bash
# é‡‡é›†å·¥ä½œçŠ¶æ€æ•°æ®
python data_collection.py \
    -cd 10 \
    -c focused_work,stress_state,fatigue_state,relaxed_state,creative_thinking \
    -f 5 \
    -r 10 \
    -t 3 \
    -cam 0 \
    --audio True \
    --noserial \
    -p ../work_state_dataset \
    -o work_session_001
```

### 3. æ¨¡å‹å®šåˆ¶

ä¿®æ”¹ `dl_model/train.py` ä¸­çš„æ¨¡å‹é…ç½®:

```python
# å·¥ä½œçŠ¶æ€æ„ŸçŸ¥ä¸“ç”¨é…ç½®
class WorkStateConfig:
    num_classes = 5  # 5ç§å·¥ä½œçŠ¶æ€
    sequence_length = 30  # 30å¸§åºåˆ—
    feature_dim = 64  # ç‰¹å¾ç»´åº¦

    # æ•°æ®å¢å¼º
    augmentation = {
        'noise_level': 0.1,
        'time_shift': 0.2,
        'amplitude_scale': 0.3
    }
```

## ğŸ“Š æ€§èƒ½ç›‘æ§

### å®æ—¶ç›‘æ§è„šæœ¬

åˆ›å»º `monitor_work_state.py`:

```python
import numpy as np
from dl_model.trace_model import TraceModel
import matplotlib.pyplot as plt

class WorkStateMonitor:
    def __init__(self, model_path):
        self.model = TraceModel(model_path)
        self.state_history = []

    def process_real_time_data(self, audio_data):
        prediction = self.model.predict(audio_data)
        self.state_history.append(prediction)
        return prediction

    def generate_report(self):
        # ç”Ÿæˆå·¥ä½œæ•ˆç‡æŠ¥å‘Š
        pass
```

### å¯è§†åŒ–ä»ªè¡¨æ¿

ä½¿ç”¨Streamlitåˆ›å»ºç›‘æ§ç•Œé¢:

```bash
pip install streamlit
streamlit run dashboard.py
```

## ğŸ§ª å®éªŒè®¾è®¡

### 1. åŸºç¡€éªŒè¯å®éªŒ
- **ç›®æ ‡**: éªŒè¯æ‰‹åŠ¿ä¸å·¥ä½œçŠ¶æ€çš„å…³è”æ€§
- **å‚ä¸è€…**: 20-30äºº
- **æ—¶é•¿**: æ¯äºº30åˆ†é’Ÿ
- **ä»»åŠ¡**: ç¼–ç¨‹ã€å†™ä½œã€è®¾è®¡ç­‰å…¸å‹å·¥ä½œ

### 2. å®æ—¶ç¯å¢ƒå®éªŒ
- **ç›®æ ‡**: éªŒè¯å®é™…å·¥ä½œç¯å¢ƒä¸­çš„æ•ˆæœ
- **å‘¨æœŸ**: 2-4å‘¨
- **æ•°æ®é‡**: 100+å°æ—¶
- **æŒ‡æ ‡**: è¯†åˆ«å‡†ç¡®ç‡ã€è¯¯æŠ¥ç‡ã€å“åº”æ—¶é—´

### 3. å•†ä¸šåŒ–éªŒè¯
- **ç›®æ ‡**: ç”¨æˆ·ä½“éªŒå’Œå•†ä¸šä»·å€¼éªŒè¯
- **è§„æ¨¡**: 100+ç”¨æˆ·
- **å‘¨æœŸ**: 3ä¸ªæœˆ
- **åé¦ˆ**: ç”¨æˆ·æ»¡æ„åº¦ã€å·¥ä½œæ•ˆç‡æå‡

## ğŸ“ˆ æ•°æ®åˆ†æ

### 1. ä¿¡å·ç‰¹å¾æå–
```python
# å£°çº³ä¿¡å·ç‰¹å¾
def extract_acoustic_features(audio_signal):
    features = {
        'spectral_centroid': librosa.feature.spectral_centroid(y=audio_signal),
        'spectral_rolloff': librosa.feature.spectral_rolloff(y=audio_signal),
        'zero_crossing_rate': librosa.feature.zero_crossing_rate(audio_signal),
        'mfcc': librosa.feature.mfcc(y=audio_signal)
    }
    return features
```

### 2. çŠ¶æ€åˆ†ç±»ç®—æ³•
```python
# å·¥ä½œçŠ¶æ€åˆ†ç±»å™¨
class WorkStateClassifier:
    def __init__(self):
        self.models = {
            'random_forest': RandomForestClassifier(),
            'svm': SVC(kernel='rbf'),
            'lstm': Sequential()
        }

    def ensemble_predict(self, features):
        predictions = []
        for model in self.models.values():
            pred = model.predict(features)
            predictions.append(pred)
        return majority_vote(predictions)
```

## ğŸ“± éƒ¨ç½²æ–¹æ¡ˆ

### 1. æœ¬åœ°éƒ¨ç½²
- **ä¼˜åŠ¿**: æ•°æ®éšç§ï¼Œä½å»¶è¿Ÿ
- **é…ç½®**: æœ¬åœ°GPUæœåŠ¡å™¨
- **æˆæœ¬**: ä¸€æ¬¡æ€§ç¡¬ä»¶æŠ•å…¥

### 2. äº‘ç«¯éƒ¨ç½²
- **ä¼˜åŠ¿**: å¯æ‰©å±•æ€§å¼ºï¼Œç»´æŠ¤ç®€å•
- **å¹³å°**: AWS/Azure/GCP
- **æˆæœ¬**: æŒ‰ä½¿ç”¨é‡ä»˜è´¹

### 3. è¾¹ç¼˜éƒ¨ç½²
- **ä¼˜åŠ¿**: å®æ—¶æ€§å¥½ï¼Œç¦»çº¿å·¥ä½œ
- **ç¡¬ä»¶**: NVIDIA Jetsonç³»åˆ—
- **æˆæœ¬**: ä¸­ç­‰ç¡¬ä»¶æŠ•å…¥

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **æ•°æ®é‡‡é›†å¤±è´¥**
   - æ£€æŸ¥éŸ³é¢‘è®¾å¤‡æƒé™
   - ç¡®è®¤ä¼ æ„Ÿå™¨è¿æ¥
   - éªŒè¯é‡‡æ ·ç‡è®¾ç½®

2. **æ¨¡å‹è®­ç»ƒæ…¢**
   - å¢åŠ batch size
   - ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
   - æ£€æŸ¥GPUåˆ©ç”¨ç‡

3. **è¯†åˆ«å‡†ç¡®ç‡ä½**
   - å¢åŠ è®­ç»ƒæ•°æ®é‡
   - è°ƒæ•´æ•°æ®å¢å¼ºç­–ç•¥
   - ä¼˜åŒ–æ¨¡å‹æ¶æ„

## ğŸ“š å­¦ä¹ èµ„æº

### æŠ€æœ¯æ–‡æ¡£
- [PyTorchå®˜æ–¹æ–‡æ¡£](https://pytorch.org/docs/)
- [LibROSAéŸ³é¢‘å¤„ç†](https://librosa.org/doc/)
- [OpenCVè®¡ç®—æœºè§†è§‰](https://opencv.org/)

### å­¦æœ¯è®ºæ–‡
- EchoWriståŸè®ºæ–‡: æŸ¥æ‰¾IEEE Xplore
- å£°çº³æ‰‹åŠ¿è¯†åˆ«ç»¼è¿°: Google Scholar
- å·¥ä½œçŠ¶æ€æ£€æµ‹ç ”ç©¶: ACM Digital Library

### ç¤¾åŒºèµ„æº
- [Stack Overflow - Gesture Recognition](https://stackoverflow.com/questions/tagged/gesture-recognition)
- [Reddit - MachineLearning](https://www.reddit.com/r/MachineLearning/)
- [GitHub - Awesome Gesture Recognition](https://github.com/topics/gesture-recognition)

## ğŸ¤ è´¡çŒ®æŒ‡å—

### å¼€å‘æµç¨‹
1. Forké¡¹ç›®åˆ°ä¸ªäººä»“åº“
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯
3. æäº¤ä»£ç å˜æ›´
4. å‘èµ·Pull Request

### ä»£ç è§„èŒƒ
- Python PEP8
- æ·»åŠ ç±»å‹æ³¨é‡Š
- ç¼–å†™å•å…ƒæµ‹è¯•
- æ›´æ–°æ–‡æ¡£

## ğŸ“ æ”¯æŒè”ç³»

- **GitHub Issues**: https://github.com/wujiajunhahah/gesture/issues
- **æŠ€æœ¯è®¨è®º**: å¾®ä¿¡ç¾¤/é’‰é’‰ç¾¤
- **å•†åŠ¡åˆä½œ**: é‚®ç®±è”ç³»

---

**æ³¨æ„**: æœ¬æŒ‡å—åŸºäºEchoWristé¡¹ç›®ï¼Œä¸“é—¨é’ˆå¯¹å·¥ä½œçŠ¶æ€æ„ŸçŸ¥åœºæ™¯è¿›è¡Œä¼˜åŒ–ã€‚å¼€å‘è¿‡ç¨‹ä¸­è¯·éµå®ˆç›¸å…³å¼€æºåè®®å’Œå­¦æœ¯è§„èŒƒã€‚