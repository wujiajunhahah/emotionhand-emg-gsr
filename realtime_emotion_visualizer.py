#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®æ—¶æƒ…ç»ªå¯è§†åŒ–å™¨ - åŸºäºEMG+GSRçš„å®æ—¶æƒ…ç»ªè¯†åˆ«ä¸å¯è§†åŒ–
ä¿®å¤å­—ä½“å’ŒçŠ¶æ€æ˜ å°„é—®é¢˜
"""

import numpy as np
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
import tkinter as tk
from tkinter import ttk
import threading
import time
from collections import deque
import queue
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®matplotlibå­—ä½“
import matplotlib
matplotlib.rcParams['font.family'] = 'DejaVu Sans'
matplotlib.rcParams['axes.unicode_minus'] = False

# å¯¼å…¥æ ¸å¿ƒæ¨¡å—
try:
    from signal_processing_engine import SignalProcessingEngine
    from emotion_state_detector import EmotionStateDetector
except ImportError:
    print("âš ï¸ æ ¸å¿ƒæ¨¡å—æœªæ‰¾åˆ°ï¼Œä½¿ç”¨æ¼”ç¤ºæ¨¡å¼")
    SignalProcessingEngine = None
    EmotionStateDetector = None

class RealtimeEmotionVisualizer:
    def __init__(self, demo_mode=True):
        self.demo_mode = demo_mode

        # åˆ›å»ºä¸»çª—å£
        self.root = tk.Tk()
        self.root.title("EmotionHand - å®æ—¶æƒ…ç»ªå¯è§†åŒ–")
        self.root.geometry("1200x800")

        # æƒ…ç»ªçŠ¶æ€å®šä¹‰
        self.emotion_states = {
            'Neutral': {'color': '#808080', 'emoji': 'ğŸ˜', 'range': (0.4, 0.6)},
            'Happy': {'color': '#FFD700', 'emoji': 'ğŸ˜Š', 'range': (0.6, 0.8)},
            'Stress': {'color': '#FF6B6B', 'emoji': 'ğŸ˜°', 'range': (0.8, 1.0)},
            'Focus': {'color': '#4ECDC4', 'emoji': 'ğŸ¯', 'range': (0.2, 0.4)},
            'Excited': {'color': '#FF1744', 'emoji': 'ğŸ¤©', 'range': (0.0, 0.2)}
        }

        # å½“å‰çŠ¶æ€
        self.current_emotion = 'Neutral'
        self.emotion_confidence = 0.5

        # æ•°æ®å­˜å‚¨
        self.emg_data = deque(maxlen=1000)
        self.gsr_data = deque(maxlen=1000)
        self.emotion_history = deque(maxlen=100)
        self.time_stamps = deque(maxlen=1000)

        # ä¿¡å·å¤„ç†ç»„ä»¶
        if SignalProcessingEngine and not demo_mode:
            self.signal_engine = SignalProcessingEngine()
            self.emotion_detector = EmotionStateDetector()
        else:
            self.signal_engine = None
            self.emotion_detector = None

        # åŠ¨ç”»ç›¸å…³
        self.animation = None
        self.is_running = False
        self.start_time = time.time()

        # è®¾ç½®ç•Œé¢
        self.setup_ui()

    def setup_ui(self):
        """è®¾ç½®ç”¨æˆ·ç•Œé¢"""
        # ä¸»æ¡†æ¶
        main_frame = ttk.Frame(self.root)
        main_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)

        # æ ‡é¢˜
        title_label = ttk.Label(main_frame, text="EmotionHand å®æ—¶æƒ…ç»ªå¯è§†åŒ–",
                               font=('Arial', 16, 'bold'))
        title_label.pack(pady=5)

        # çŠ¶æ€æ˜¾ç¤ºæ¡†æ¶
        status_frame = ttk.LabelFrame(main_frame, text="å½“å‰çŠ¶æ€", padding=10)
        status_frame.pack(fill=tk.X, pady=5)

        # æƒ…ç»ªçŠ¶æ€æ˜¾ç¤º
        self.emotion_label = ttk.Label(status_frame,
                                      text=f"ğŸ˜ å¹³é™ - ç½®ä¿¡åº¦: 0.50",
                                      font=('Arial', 14))
        self.emotion_label.pack()

        # æ¨¡å¼æ˜¾ç¤º
        mode_text = "æ¼”ç¤ºæ¨¡å¼" if self.demo_mode else "å®æ—¶æ¨¡å¼"
        self.mode_label = ttk.Label(status_frame, text=f"æ¨¡å¼: {mode_text}")
        self.mode_label.pack()

        # åˆ›å»ºå›¾å½¢åŒºåŸŸ
        self.setup_plots(main_frame)

        # æ§åˆ¶æŒ‰é’®
        control_frame = ttk.Frame(main_frame)
        control_frame.pack(fill=tk.X, pady=10)

        self.start_btn = ttk.Button(control_frame, text="å¼€å§‹ç›‘æµ‹",
                                   command=self.start_monitoring)
        self.start_btn.pack(side=tk.LEFT, padx=5)

        self.stop_btn = ttk.Button(control_frame, text="åœæ­¢ç›‘æµ‹",
                                  command=self.stop_monitoring,
                                  state=tk.DISABLED)
        self.stop_btn.pack(side=tk.LEFT, padx=5)

        if self.demo_mode:
            ttk.Label(control_frame,
                     text="æ¼”ç¤ºæ¨¡å¼ï¼šè‡ªåŠ¨ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®é©±åŠ¨çŠ¶æ€å˜åŒ–").pack(side=tk.LEFT, padx=20)

    def setup_plots(self, parent):
        """è®¾ç½®å›¾è¡¨"""
        # åˆ›å»ºmatplotlibå›¾å½¢
        self.fig = plt.Figure(figsize=(12, 6), facecolor='white')

        # EMGä¿¡å·å›¾
        self.ax_emg = self.fig.add_subplot(131)
        self.ax_emg.set_title('EMGä¿¡å·')
        self.ax_emg.set_xlabel('æ—¶é—´ (s)')
        self.ax_emg.set_ylabel('å¹…å€¼')
        self.ax_emg.grid(True, alpha=0.3)
        self.ax_emg.set_ylim(-1, 1)

        # GSRä¿¡å·å›¾
        self.ax_gsr = self.fig.add_subplot(132)
        self.ax_gsr.set_title('GSRä¿¡å·')
        self.ax_gsr.set_xlabel('æ—¶é—´ (s)')
        self.ax_gsr.set_ylabel('ç”µå¯¼ (Î¼S)')
        self.ax_gsr.grid(True, alpha=0.3)
        self.ax_gsr.set_ylim(0, 5)

        # æƒ…ç»ªçŠ¶æ€å›¾
        self.ax_emotion = self.fig.add_subplot(133)
        self.ax_emotion.set_title('æƒ…ç»ªçŠ¶æ€æ—¶é—´çº¿')
        self.ax_emotion.set_xlabel('æ—¶é—´ (s)')
        self.ax_emotion.set_ylabel('æƒ…ç»ªçŠ¶æ€')
        self.ax_emotion.set_ylim(-0.5, len(self.emotion_states) - 0.5)
        self.ax_emotion.set_yticks(range(len(self.emotion_states)))
        self.ax_emotion.set_yticklabels(list(self.emotion_states.keys()))
        self.ax_emotion.grid(True, alpha=0.3)

        # è®¾ç½®å›¾å½¢å¸ƒå±€
        self.fig.tight_layout()

        # åµŒå…¥åˆ°tkinter
        self.canvas = FigureCanvasTkAgg(self.fig, parent)
        self.canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)

    def generate_demo_data(self):
        """ç”Ÿæˆæ¼”ç¤ºæ•°æ®"""
        current_time = time.time() - self.start_time

        # ç”Ÿæˆå‘¨æœŸæ€§å˜åŒ–çš„æ¨¡æ‹Ÿæ•°æ®
        emg_signal = 0.3 * np.sin(2 * np.pi * 0.5 * current_time)  # 0.5Hz
        emg_signal += 0.1 * np.sin(2 * np.pi * 5 * current_time)   # 5Hz
        emg_signal += 0.05 * np.random.randn()  # å™ªå£°

        gsr_signal = 2.0 + 0.5 * np.sin(2 * np.pi * 0.1 * current_time)  # 0.1Hz
        gsr_signal += 0.1 * np.random.randn()  # å™ªå£°
        gsr_signal = max(0.5, gsr_signal)  # ç¡®ä¿éè´Ÿ

        # æ ¹æ®æ—¶é—´è‡ªåŠ¨åˆ‡æ¢æƒ…ç»ªçŠ¶æ€
        emotion_cycle_time = 30  # 30ç§’ä¸€ä¸ªå‘¨æœŸ
        phase = (current_time % emotion_cycle_time) / emotion_cycle_time

        if phase < 0.2:
            target_emotion = 'Neutral'
        elif phase < 0.4:
            target_emotion = 'Focus'
        elif phase < 0.6:
            target_emotion = 'Happy'
        elif phase < 0.8:
            target_emotion = 'Excited'
        else:
            target_emotion = 'Stress'

        # æ·»åŠ æƒ…ç»ªç›¸å…³çš„ä¿¡å·ç‰¹å¾
        if target_emotion == 'Stress':
            emg_signal += 0.2 * np.random.randn()
            gsr_signal += 0.3
        elif target_emotion == 'Excited':
            emg_signal += 0.15 * np.sin(2 * np.pi * 10 * current_time)
            gsr_signal += 0.2
        elif target_emotion == 'Happy':
            emg_signal += 0.1 * np.sin(2 * np.pi * 3 * current_time)
        elif target_emotion == 'Focus':
            emg_signal *= 0.7  # é™ä½ä¿¡å·å˜åŒ–

        return emg_signal, gsr_signal, target_emotion

    def process_real_data(self, emg_raw, gsr_raw):
        """å¤„ç†çœŸå®æ•°æ®"""
        if self.signal_engine and self.emotion_detector:
            try:
                # ä¿¡å·å¤„ç†
                emg_processed = self.signal_engine.process_emg(emg_raw)
                gsr_processed = self.signal_engine.process_gsr(gsr_raw)

                # æƒ…ç»ªæ£€æµ‹
                emotion_result = self.emotion_detector.detect_emotion(
                    emg_processed, gsr_processed
                )

                if emotion_result:
                    return np.mean(emg_processed), gsr_processed, emotion_result['emotion']
            except Exception as e:
                print(f"âŒ æ•°æ®å¤„ç†é”™è¯¯: {e}")

        return np.mean(emg_raw), gsr_raw, 'Neutral'

    def update_data(self):
        """æ›´æ–°æ•°æ®"""
        current_time = time.time() - self.start_time

        if self.demo_mode:
            # ç”Ÿæˆæ¼”ç¤ºæ•°æ®
            emg_val, gsr_val, emotion = self.generate_demo_data()
        else:
            # è¿™é‡Œåº”è¯¥ä»ä¼ æ„Ÿå™¨è·å–æ•°æ®
            # æš‚æ—¶ç”¨æ¼”ç¤ºæ•°æ®ä»£æ›¿
            emg_val, gsr_val, emotion = self.generate_demo_data()

        # æ›´æ–°å½“å‰æƒ…ç»ª
        self.current_emotion = emotion
        self.emotion_confidence = 0.7 + 0.2 * np.random.random()  # æ¨¡æ‹Ÿç½®ä¿¡åº¦

        # å­˜å‚¨æ•°æ®
        self.emg_data.append(emg_val)
        self.gsr_data.append(gsr_val)
        self.emotion_history.append(emotion)
        self.time_stamps.append(current_time)

    def update_plots(self, frame):
        """æ›´æ–°å›¾è¡¨"""
        if not self.is_running:
            return

        # æ›´æ–°æ•°æ®
        self.update_data()

        # æ›´æ–°EMGå›¾
        self.ax_emg.clear()
        self.ax_emg.set_title('EMGä¿¡å·')
        self.ax_emg.set_xlabel('æ—¶é—´ (s)')
        self.ax_emg.set_ylabel('å¹…å€¼')
        self.ax_emg.grid(True, alpha=0.3)

        if len(self.emg_data) > 0:
            times = list(self.time_stamps)
            emg_values = list(self.emg_data)
            self.ax_emg.plot(times, emg_values,
                           color=self.emotion_states[self.current_emotion]['color'],
                           linewidth=1.5, alpha=0.8)
            self.ax_emg.set_ylim(-1, 1)

        # æ›´æ–°GSRå›¾
        self.ax_gsr.clear()
        self.ax_gsr.set_title('GSRä¿¡å·')
        self.ax_gsr.set_xlabel('æ—¶é—´ (s)')
        self.ax_gsr.set_ylabel('ç”µå¯¼ (Î¼S)')
        self.ax_gsr.grid(True, alpha=0.3)

        if len(self.gsr_data) > 0:
            times = list(self.time_stamps)
            gsr_values = list(self.gsr_data)
            self.ax_gsr.plot(times, gsr_values,
                           color=self.emotion_states[self.current_emotion]['color'],
                           linewidth=1.5, alpha=0.8)
            self.ax_gsr.set_ylim(0, 5)

        # æ›´æ–°æƒ…ç»ªçŠ¶æ€å›¾
        self.ax_emotion.clear()
        self.ax_emotion.set_title('æƒ…ç»ªçŠ¶æ€æ—¶é—´çº¿')
        self.ax_emotion.set_xlabel('æ—¶é—´ (s)')
        self.ax_emotion.set_ylabel('æƒ…ç»ªçŠ¶æ€')
        self.ax_emotion.set_ylim(-0.5, len(self.emotion_states) - 0.5)
        self.ax_emotion.set_yticks(range(len(self.emotion_states)))
        self.ax_emotion.set_yticklabels(list(self.emotion_states.keys()))
        self.ax_emotion.grid(True, alpha=0.3)

        if len(self.emotion_history) > 0:
            times = list(self.time_stamps)[-len(self.emotion_history):]
            emotion_values = []
            emotion_colors = []

            for emotion in self.emotion_history:
                if emotion in self.emotion_states:
                    idx = list(self.emotion_states.keys()).index(emotion)
                    emotion_values.append(idx)
                    emotion_colors.append(self.emotion_states[emotion]['color'])
                else:
                    # å¤„ç†æœªçŸ¥æƒ…ç»ªçŠ¶æ€
                    idx = list(self.emotion_states.keys()).index('Neutral')
                    emotion_values.append(idx)
                    emotion_colors.append(self.emotion_states['Neutral']['color'])

            self.ax_emotion.scatter(times, emotion_values, c=emotion_colors, s=20, alpha=0.6)

        # æ›´æ–°çŠ¶æ€æ ‡ç­¾
        emotion_info = self.emotion_states.get(self.current_emotion, self.emotion_states['Neutral'])
        self.emotion_label.config(
            text=f"{emotion_info['emoji']} {self.current_emotion} - ç½®ä¿¡åº¦: {self.emotion_confidence:.2f}"
        )

        # åˆ·æ–°ç”»å¸ƒ
        self.canvas.draw()

    def start_monitoring(self):
        """å¼€å§‹ç›‘æµ‹"""
        if not self.is_running:
            self.is_running = True
            self.start_time = time.time()
            self.start_btn.config(state=tk.DISABLED)
            self.stop_btn.config(state=tk.NORMAL)

            # åˆ›å»ºåŠ¨ç”» - ä»matplotlib.animationå¯¼å…¥
            from matplotlib.animation import FuncAnimation
            self.animation = FuncAnimation(self.fig, self.update_plots,
                                         interval=100, blit=False)
            self.canvas.draw()

            print("âœ… å¼€å§‹å®æ—¶ç›‘æµ‹")

    def stop_monitoring(self):
        """åœæ­¢ç›‘æµ‹"""
        if self.is_running:
            self.is_running = False
            self.start_btn.config(state=tk.NORMAL)
            self.stop_btn.config(state=tk.DISABLED)

            if self.animation is not None:
                self.animation.event_source.stop()
                self.animation = None

            print("â¹ï¸ åœæ­¢ç›‘æµ‹")

    def run(self):
        """è¿è¡Œåº”ç”¨"""
        def on_closing():
            if self.is_running:
                self.stop_monitoring()
            self.root.quit()
            self.root.destroy()

        self.root.protocol("WM_DELETE_WINDOW", on_closing)

        print("ğŸš€ EmotionHand å®æ—¶æƒ…ç»ªå¯è§†åŒ–å™¨å¯åŠ¨")
        print(f"ğŸ“Š å½“å‰æ¨¡å¼: {'æ¼”ç¤ºæ¨¡å¼' if self.demo_mode else 'å®æ—¶æ¨¡å¼'}")
        print("ğŸ“‹ ä½¿ç”¨è¯´æ˜:")
        print("   â€¢ ç‚¹å‡»'å¼€å§‹ç›‘æµ‹'å¼€å§‹å®æ—¶å¯è§†åŒ–")
        print("   â€¢ è§‚å¯ŸEMG/GSRä¿¡å·å’Œæƒ…ç»ªçŠ¶æ€å˜åŒ–")
        if self.demo_mode:
            print("   â€¢ æ¼”ç¤ºæ¨¡å¼ä¼šè‡ªåŠ¨ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®")

        self.root.mainloop()

if __name__ == "__main__":
    # é»˜è®¤ä½¿ç”¨æ¼”ç¤ºæ¨¡å¼
    visualizer = RealtimeEmotionVisualizer(demo_mode=True)
    visualizer.run()