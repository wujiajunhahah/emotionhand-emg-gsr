#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
EmotionHand é™æ€æ‰‹éƒ¨æ¨¡å‹æ¼”ç¤º
å±•ç¤º3Dæ‰‹éƒ¨æ¨¡å‹å’Œä¸åŒæ‰‹åŠ¿çŠ¶æ€
"""

import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from mpl_toolkits.mplot3d.art3d import Poly3DCollection
import matplotlib.patches as mpatches

# è®¾ç½®å­—ä½“
plt.rcParams['font.family'] = ['DejaVu Sans', 'Arial Unicode MS', 'SimHei']
plt.rcParams['axes.unicode_minus'] = False

class HandModel3D:
    """3Dæ‰‹éƒ¨æ¨¡å‹"""

    def __init__(self):
        # æ‰‹éƒ¨å‡ ä½•å‚æ•°
        self.palm_length = 0.85
        self.palm_width = 0.85
        self.finger_lengths = [0.65, 0.75, 0.70, 0.55]  # é£ŸæŒ‡åˆ°å°æŒ‡
        self.thumb_length = 0.55
        self.finger_width = 0.18

        # æ‰‹åŠ¿å¼¯æ›²è§’åº¦
        self.gesture_bends = {
            'Fist': [85, 80, 75, 70],
            'Open': [5, 5, 5, 5],
            'Pinch': [10, 75, 80, 85],
            'Point': [10, 10, 10, 80],
            'Peace': [10, 10, 10, 10],
            'Neutral': [20, 20, 20, 20]
        }

        # çŠ¶æ€é¢œè‰²
        self.state_colors = {
            'Relaxed': '#3498db',      # è“è‰²
            'Focused': '#2ecc71',      # ç»¿è‰²
            'Stressed': '#e74c3c',     # çº¢è‰²
            'Fatigued': '#f39c12'      # é»„è‰²
        }

    def get_finger_joints(self, gesture: str, finger_idx: int) -> list:
        """è®¡ç®—æ‰‹æŒ‡å…³èŠ‚ä½ç½®"""
        bend_angles = self.gesture_bends.get(gesture, [20, 20, 20, 20])
        bend_angle = bend_angles[min(finger_idx, 3)]

        # æ‰‹æŒ‡æ ¹éƒ¨ä½ç½®
        if finger_idx == 0:  # æ‹‡æŒ‡
            base_x, base_y, base_z = -self.palm_width/2, 0, 0
        else:  # å…¶ä»–æ‰‹æŒ‡
            finger_spacing = self.palm_width / 5
            base_x = -self.palm_width/2 + finger_spacing * finger_idx
            base_y, base_z = self.palm_length, 0

        joints = [(base_x, base_y, base_z)]

        # è®¡ç®—å¼¯æ›²åçš„å…³èŠ‚ä½ç½®
        length = self.finger_lengths[min(finger_idx, 3)]
        segments = 3
        segment_length = length / segments

        current_x, current_y, current_z = base_x, base_y, base_z

        for i in range(segments):
            bend_rad = np.radians(bend_angle * (i + 1) / segments)
            current_x += segment_length * np.sin(bend_rad) * 0.3
            current_y += segment_length * np.cos(bend_rad)
            current_z += segment_length * np.sin(bend_rad) * 0.2 * (1 if i % 2 == 0 else -1)
            joints.append((current_x, current_y, current_z))

        return joints

    def draw_hand(self, ax, gesture: str, state: str, title: str):
        """ç»˜åˆ¶3Dæ‰‹éƒ¨æ¨¡å‹"""

        # è®¾ç½®é¢œè‰²
        hand_color = self.state_colors.get(state, '#95a5a6')

        # ç»˜åˆ¶æ‰‹æŒ
        palm_corners = [
            [-self.palm_width/2, 0, -self.palm_width/2],
            [self.palm_width/2, 0, -self.palm_width/2],
            [self.palm_width/2, 0, self.palm_width/2],
            [-self.palm_width/2, 0, self.palm_width/2]
        ]

        # æ‰‹æŒé¡¶é¢
        palm_top = [[p[0], p[1] + 0.1, p[2]] for p in palm_corners]
        palm_collection = Poly3DCollection([palm_top], alpha=0.7,
                                          facecolor=hand_color, edgecolor='black', linewidth=1)
        ax.add_collection3d(palm_collection)

        # ç»˜åˆ¶æ‰‹æŒ‡
        for finger_idx in range(5):
            joints = self.get_finger_joints(gesture, finger_idx)
            xs, ys, zs = zip(*joints)
            ax.plot(xs, ys, zs, 'o-', color=hand_color, linewidth=3,
                   markersize=6, markerfacecolor=hand_color, markeredgecolor='black')

        # è®¾ç½®åæ ‡è½´
        ax.set_xlim([-1, 1])
        ax.set_ylim([0, 2])
        ax.set_zlim([-1, 1])
        ax.set_xlabel('X')
        ax.set_ylabel('Y')
        ax.set_zlabel('Z')

        # è®¾ç½®æ ‡é¢˜å’Œè§†è§’
        ax.set_title(f'{title}\n{gesture} | {state}', fontsize=10, fontweight='bold')
        ax.view_init(elev=20, azim=45)

        # æ·»åŠ ç½‘æ ¼
        ax.grid(True, alpha=0.3)

def create_demo_visualization():
    """åˆ›å»ºæ¼”ç¤ºå¯è§†åŒ–"""

    print("ğŸ­ åˆ›å»º EmotionHand æ‰‹éƒ¨æ¨¡å‹æ¼”ç¤º...")

    # åˆ›å»ºæ‰‹éƒ¨æ¨¡å‹
    hand_model = HandModel3D()

    # åˆ›å»º3x2çš„å­å›¾å¸ƒå±€
    fig = plt.figure(figsize=(15, 12))
    fig.suptitle('ğŸ­ EmotionHand - 3D Hand Model Visualization\n'
                 'Real-time EMG+GSR Emotion Recognition System',
                 fontsize=16, fontweight='bold')

    # å®šä¹‰æ¼”ç¤ºåœºæ™¯
    scenarios = [
        ('Open', 'Relaxed', 'Relaxed State - Open Hand'),
        ('Fist', 'Stressed', 'Stressed State - Closed Fist'),
        ('Pinch', 'Focused', 'Focused State - Pinch Gesture'),
        ('Point', 'Focused', 'Focused State - Pointing'),
        ('Peace', 'Relaxed', 'Relaxed State - Peace Sign'),
        ('Neutral', 'Fatigued', 'Fatigued State - Neutral')
    ]

    # ç»˜åˆ¶6ä¸ªä¸åŒçš„æ‰‹éƒ¨çŠ¶æ€
    for i, (gesture, state, title) in enumerate(scenarios):
        ax = fig.add_subplot(3, 2, i+1, projection='3d')
        hand_model.draw_hand(ax, gesture, state, title)

    plt.tight_layout()

    # æ·»åŠ é¢œè‰²å›¾ä¾‹
    legend_elements = [
        mpatches.Patch(color='#3498db', label='Relaxed (æ”¾æ¾)'),
        mpatches.Patch(color='#2ecc71', label='Focused (ä¸“æ³¨)'),
        mpatches.Patch(color='#e74c3c', label='Stressed (å‹åŠ›)'),
        mpatches.Patch(color='#f39c12', label='Fatigued (ç–²åŠ³)')
    ]
    plt.legend(handles=legend_elements, loc='lower center', ncol=4,
               bbox_to_anchor=(0.5, -0.02), fontsize=10)

    # æ·»åŠ æŠ€æœ¯ä¿¡æ¯
    tech_info = """
    ğŸ“Š Technical Specifications:
    â€¢ EMG: 8-channel, 1000Hz sampling rate
    â€¢ GSR: Single-channel, 100Hz sampling rate
    â€¢ Features: RMS, MDF, ZC, WL + GSR statistics
    â€¢ Algorithms: LightGBM, SVM, LDA
    â€¢ Real-time latency: <100ms
    â€¢ Calibration time: 2 minutes
    â€¢ Visualization: Unity 3D with particle effects
    """

    fig.text(0.02, 0.02, tech_info, fontsize=8, verticalalignment='bottom',
            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))

    # ä¿å­˜å›¾ç‰‡
    plt.savefig('EmotionHand_Hand_Model_Demo.png', dpi=300, bbox_inches='tight')
    print("âœ… æ¼”ç¤ºå›¾ç‰‡å·²ä¿å­˜: EmotionHand_Hand_Model_Demo.png")

    plt.show()

def create_signal_demo():
    """åˆ›å»ºä¿¡å·æ¼”ç¤º"""

    print("ğŸ“Š åˆ›å»º EMG+GSR ä¿¡å·æ¼”ç¤º...")

    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    fig.suptitle('ğŸ“ˆ EmotionHand - Signal Analysis Demo\n'
                 'EMG+GSR Dual-Modal Emotion Recognition',
                 fontsize=14, fontweight='bold')

    # æ¨¡æ‹Ÿæ—¶é—´è½´
    t = np.linspace(0, 2, 1000)

    # 1. EMGä¿¡å·å›¾
    ax1 = axes[0, 0]
    emg_channels = 4  # æ˜¾ç¤ºå‰4é€šé“

    for i in range(emg_channels):
        # ä¸åŒæ‰‹åŠ¿çš„ç‰¹å¾é¢‘ç‡
        if i == 0:  # Fist
            freq = 30 + 10*i
            amplitude = 0.8
        elif i == 1:  # Open
            freq = 15 + 5*i
            amplitude = 0.3
        elif i == 2:  # Pinch
            freq = 40 + 15*i
            amplitude = 0.6
        else:  # Point
            freq = 25 + 8*i
            amplitude = 0.5

        signal = amplitude * np.sin(2 * np.pi * freq * t)
        signal += 0.1 * np.random.randn(len(t))  # å™ªå£°
        signal += i * 0.5  # é€šé“åç§»

        ax1.plot(t, signal, alpha=0.8, linewidth=1.5, label=f'Channel {i+1}')

    ax1.set_title('EMG Signals (8 Channels)', fontweight='bold')
    ax1.set_xlabel('Time (s)')
    ax1.set_ylabel('Amplitude (with offset)')
    ax1.legend(loc='upper right')
    ax1.grid(True, alpha=0.3)

    # 2. GSRä¿¡å·å›¾
    ax2 = axes[0, 1]
    # æ¨¡æ‹Ÿä¸åŒçŠ¶æ€çš„GSRä¿¡å·
    gsr_states = {
        'Relaxed': 0.1 + 0.05 * np.sin(2 * np.pi * 0.5 * t),
        'Focused': 0.2 + 0.08 * np.sin(2 * np.pi * 0.8 * t),
        'Stressed': 0.4 + 0.15 * np.sin(2 * np.pi * 1.2 * t) + 0.1 * np.random.randn(len(t)),
        'Fatigued': 0.25 + 0.12 * np.sin(2 * np.pi * 0.6 * t)
    }

    colors = {'Relaxed': '#3498db', 'Focused': '#2ecc71',
              'Stressed': '#e74c3c', 'Fatigued': '#f39c12'}

    for state, signal in gsr_states.items():
        ax2.plot(t, signal, label=state, color=colors[state], linewidth=2)

    ax2.set_title('GSR Signals for Different States', fontweight='bold')
    ax2.set_xlabel('Time (s)')
    ax2.set_ylabel('GSR Value')
    ax2.legend(loc='upper right')
    ax2.grid(True, alpha=0.3)

    # 3. ç‰¹å¾åˆ†æå›¾
    ax3 = axes[1, 0]
    features = ['RMS', 'STD', 'ZC', 'WL', 'GSR-Mean', 'GSR-STD']

    # æ¨¡æ‹Ÿä¸åŒæ‰‹åŠ¿çš„ç‰¹å¾å€¼
    feature_values = {
        'Fist': [0.8, 0.3, 120, 45, 0.4, 0.12],
        'Open': [0.2, 0.1, 20, 8, 0.1, 0.05],
        'Pinch': [0.6, 0.25, 80, 32, 0.3, 0.08],
        'Point': [0.4, 0.18, 60, 25, 0.25, 0.07]
    }

    x = np.arange(len(features))
    width = 0.2

    for i, (gesture, values) in enumerate(feature_values.items()):
        ax3.bar(x + i*width, values, width, label=gesture, alpha=0.8)

    ax3.set_title('Feature Analysis by Gesture', fontweight='bold')
    ax3.set_xlabel('Features')
    ax3.set_ylabel('Feature Value')
    ax3.set_xticks(x + width * 1.5)
    ax3.set_xticklabels(features, rotation=45)
    ax3.legend(loc='upper right')
    ax3.grid(True, alpha=0.3)

    # 4. æ€§èƒ½æŒ‡æ ‡å›¾
    ax4 = axes[1, 1]
    metrics = ['Latency (ms)', 'Accuracy (%)', 'Calibration (min)', 'FPS']
    achieved = [85, 87, 2, 50]
    targets = [100, 80, 5, 30]

    x = np.arange(len(metrics))
    width = 0.35

    bars1 = ax4.bar(x - width/2, achieved, width, label='Achieved', color='#2ecc71', alpha=0.8)
    bars2 = ax4.bar(x + width/2, targets, width, label='Target', color='#95a5a6', alpha=0.8)

    ax4.set_title('Performance Metrics', fontweight='bold')
    ax4.set_ylabel('Value')
    ax4.set_xticks(x)
    ax4.set_xticklabels(metrics)
    ax4.legend(loc='upper right')
    ax4.grid(True, alpha=0.3)

    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bars in [bars1, bars2]:
        for bar in bars:
            height = bar.get_height()
            ax4.text(bar.get_x() + bar.get_width()/2., height,
                    f'{height}', ha='center', va='bottom', fontsize=9)

    plt.tight_layout()

    # ä¿å­˜å›¾ç‰‡
    plt.savefig('EmotionHand_Signal_Analysis_Demo.png', dpi=300, bbox_inches='tight')
    print("âœ… ä¿¡å·åˆ†æå›¾ç‰‡å·²ä¿å­˜: EmotionHand_Signal_Analysis_Demo.png")

    plt.show()

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 70)
    print("ğŸ­ EmotionHand æ‰‹éƒ¨æ¨¡å‹å’Œä¿¡å·æ¼”ç¤º")
    print("=" * 70)
    print("ğŸ“‹ æ¼”ç¤ºå†…å®¹:")
    print("  1. 3Dæ‰‹éƒ¨æ¨¡å‹ - 6ç§æ‰‹åŠ¿å’ŒçŠ¶æ€ç»„åˆ")
    print("  2. EMGä¿¡å·åˆ†æ - 8é€šé“å®æ—¶ä¿¡å·")
    print("  3. GSRä¿¡å·åˆ†æ - 4ç§æƒ…ç»ªçŠ¶æ€")
    print("  4. ç‰¹å¾åˆ†æ - RMS, STD, ZC, WL")
    print("  5. æ€§èƒ½æŒ‡æ ‡ - å»¶è¿Ÿã€ç²¾åº¦ã€æ ¡å‡†æ—¶é—´")
    print("\nğŸ¨ é¢œè‰²æ˜ å°„:")
    print("  ğŸ”µ Relaxed (æ”¾æ¾) - è“è‰²")
    print("  ğŸŸ¢ Focused (ä¸“æ³¨) - ç»¿è‰²")
    print("  ğŸ”´ Stressed (å‹åŠ›) - çº¢è‰²")
    print("  ğŸŸ¡ Fatigued (ç–²åŠ³) - é»„è‰²")
    print("=" * 70)

    # åˆ›å»ºæ¼”ç¤º
    create_demo_visualization()
    create_signal_demo()

    print("\nğŸ‰ æ¼”ç¤ºå®Œæˆ!")
    print("ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
    print("  â€¢ EmotionHand_Hand_Model_Demo.png - 3Dæ‰‹éƒ¨æ¨¡å‹æ¼”ç¤º")
    print("  â€¢ EmotionHand_Signal_Analysis_Demo.png - ä¿¡å·åˆ†ææ¼”ç¤º")
    print("\nğŸš€ è¿™äº›å›¾ç‰‡å±•ç¤ºäº†EmotionHandç³»ç»Ÿçš„æ ¸å¿ƒåŠŸèƒ½å’Œè§†è§‰æ•ˆæœ!")

if __name__ == "__main__":
    main()